{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN_own_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "55b3317418144d22ad41ddfc94ae7a98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_227683ee024f4eb8975c2c68e75d1fc3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_433eabe9eb1c4f44acca630d22e84be9",
              "IPY_MODEL_946d6f46cb204b1a80d3825bc926ba88"
            ]
          }
        },
        "227683ee024f4eb8975c2c68e75d1fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "433eabe9eb1c4f44acca630d22e84be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_03488427d3954a9f8169cd652dc52c9c",
            "_dom_classes": [],
            "description": "Epoch 34:  55%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 42,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 24,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd72cc1a1df847ae85f402526ccc321a"
          }
        },
        "946d6f46cb204b1a80d3825bc926ba88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d845f448d37b47a1ac3f52f51d8d4c6f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 23/42 [07:18&lt;06:02, 19.08s/it, d_loss=0.324, g_loss=1.91, loss=1.090, v_num=7a814cad52054ceab0ae6785560e63cc]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5b9ebc9161a42eaa47da2779209e486"
          }
        },
        "03488427d3954a9f8169cd652dc52c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd72cc1a1df847ae85f402526ccc321a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d845f448d37b47a1ac3f52f51d8d4c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5b9ebc9161a42eaa47da2779209e486": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA40qBW9XGmN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "7cc5354c-ae07-401c-f747-12d7fd6e5907"
      },
      "source": [
        "!pip install pytorch_lightning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.6/dist-packages (0.7.3)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (0.18.2)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (2.2.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (4.45.0)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (1.18.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (0.4.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.28.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.12.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.7.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.6.0.post3)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (0.9.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (3.2.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (2.21.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (46.1.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHbF974cdge6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "08b5e505-fc6a-4e0b-fc9b-98aeab766355"
      },
      "source": [
        "!pip install comet_ml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: comet_ml in /usr/local/lib/python3.6/dist-packages (3.1.4)\n",
            "Requirement already satisfied: netifaces>=0.10.7 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.10.9)\n",
            "Requirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.57.0)\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (3.7.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.12.0)\n",
            "Requirement already satisfied: everett[ini]>=1.0.1; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.0.2)\n",
            "Requirement already satisfied: comet-git-pure>=0.19.11 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.19.15)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.0.0)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (7.352.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.21.0)\n",
            "Requirement already satisfied: configobj; extra == \"ini\" in /usr/local/lib/python3.6/dist-packages (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet_ml) (5.0.6)\n",
            "Requirement already satisfied: urllib3>=1.24.1 in /usr/local/lib/python3.6/dist-packages (from comet-git-pure>=0.19.11->comet_ml) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from comet-git-pure>=0.19.11->comet_ml) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (2.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfpoXvypdghx"
      },
      "source": [
        "# used fo TPU\n",
        "# Uncomment if you want to use TPU\n",
        "# import collections\n",
        "# from datetime import datetime, timedelta\n",
        "# import os\n",
        "# import requests\n",
        "# import threading\n",
        "\n",
        "# _VersionConfig = collections.namedtuple('_VersionConfig', 'wheels,server')\n",
        "# VERSION = \"xrt==1.15.0\"  #@param [\"xrt==1.15.0\", \"torch_xla==nightly\"]\n",
        "# CONFIG = {\n",
        "#     'xrt==1.15.0': _VersionConfig('1.15', '1.15.0'),\n",
        "#     'torch_xla==nightly': _VersionConfig('nightly', 'XRT-dev{}'.format(\n",
        "#         (datetime.today() - timedelta(1)).strftime('%Y%m%d'))),\n",
        "# }[VERSION]\n",
        "# DIST_BUCKET = 'gs://tpu-pytorch/wheels'\n",
        "# TORCH_WHEEL = 'torch-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
        "# TORCH_XLA_WHEEL = 'torch_xla-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
        "# TORCHVISION_WHEEL = 'torchvision-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
        "\n",
        "# # Update TPU XRT version\n",
        "# def update_server_xrt():\n",
        "#   print('Updating server-side XRT to {} ...'.format(CONFIG.server))\n",
        "#   url = 'http://{TPU_ADDRESS}:8475/requestversion/{XRT_VERSION}'.format(\n",
        "#       TPU_ADDRESS=os.environ['COLAB_TPU_ADDR'].split(':')[0],\n",
        "#       XRT_VERSION=CONFIG.server,\n",
        "#   )\n",
        "#   print('Done updating server-side XRT: {}'.format(requests.post(url)))\n",
        "\n",
        "# update = threading.Thread(target=update_server_xrt)\n",
        "#update.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyOn4eIfp2UJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "acef12a7-e3f6-45df-9c3d-3e9e10a8be7b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEGAS8oCdgkJ"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import loggers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgJHNQhpkU2U"
      },
      "source": [
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0.0, std=0.1):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "        \n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nL-omAKdgmZ"
      },
      "source": [
        "class Discriminator(pl.LightningModule):\n",
        "  def __init__(self, ndf):\n",
        "      super().__init__()\n",
        "      self.ndf = ndf\n",
        "\n",
        "      self.fc1 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=3, out_channels=self.ndf, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "          nn.LeakyReLU(0.2)\n",
        "      )\n",
        "      self.fc2 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=self.ndf, out_channels=self.ndf * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "          nn.LeakyReLU(0.2)\n",
        "      )\n",
        "      self.fc3 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=self.ndf * 2, out_channels=self.ndf * 4, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "          nn.LeakyReLU(0.2)\n",
        "      )\n",
        "      self.fc4 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=self.ndf * 4, out_channels=self.ndf * 8, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "          nn.LeakyReLU(0.2)\n",
        "      )\n",
        "      self.fc5 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=self.ndf * 8, out_channels=self.ndf * 6, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "          nn.LeakyReLU(0.2)\n",
        "      )\n",
        "\n",
        "      self.fc6 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=self.ndf * 6, out_channels=self.ndf * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "          nn.LeakyReLU(0.2)\n",
        "      )\n",
        "\n",
        "      self.fc7 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=self.ndf * 2, out_channels=1, kernel_size=4, stride=3, padding=0, bias=False),\n",
        "          nn.Sigmoid()\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "    x = self.fc4(x)\n",
        "    x = self.fc5(x)\n",
        "    x = self.fc6(x)\n",
        "    x = self.fc7(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E03Y1veMdgoo"
      },
      "source": [
        "class Generator(pl.LightningModule):\n",
        "  def __init__(self, latent_dim, ngf):\n",
        "    super().__init__()\n",
        "    self.ngf = 16\n",
        "    self.n_features = latent_dim\n",
        "\n",
        "    self.fc1 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels=self.n_features, out_channels=self.ngf * 8, kernel_size=4, stride=2, padding=0, bias=False),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "    self.fc2 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(self.ngf * 8, self.ngf * 6, 4, 2, 1, False),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "    self.fc3 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(self.ngf * 6, self.ngf * 4, 4, 2, 1, False),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "    self.fc4 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(self.ngf * 4, self.ngf * 2, 4, 2, 1, False),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "    self.fc5 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels=self.ngf * 2, out_channels=self.ngf, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "    self.fc6 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels=self.ngf, out_channels=int(self.ngf / 2), kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "    self.fc7 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels=int(self.ngf / 2), out_channels=3, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "    x = self.fc4(x)\n",
        "    x = self.fc5(x)\n",
        "    x = self.fc6(x)\n",
        "    x = self.fc7(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WShQmCosdgqv"
      },
      "source": [
        "class DCGAN(pl.LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super().__init__()\n",
        "        self.hparams = hparams\n",
        "\n",
        "        self.generator = Generator(hparams.latent_dim, hparams.ngf)\n",
        "        self.discriminator = Discriminator(hparams.ndf)\n",
        "\n",
        "        self.AddGaussianNoise = AddGaussianNoise()\n",
        "\n",
        "        # cache for generated images\n",
        "        self.generated_imgs = None\n",
        "        self.last_imgs = None\n",
        "\n",
        "        # For experience replay\n",
        "        self.exp_replay = torch.tensor([])\n",
        "\n",
        "    def binary_cross_entropy(self, y_hat, y):\n",
        "        return F.binary_cross_entropy(y_hat, y)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.generator(x)\n",
        "\n",
        "    def training_step(self, batch, batch_nb, optimizer_idx):\n",
        "        img = batch[0]\n",
        "        self.last_imgs = img\n",
        "\n",
        "        # Train Generator\n",
        "        if optimizer_idx == 0:\n",
        "            noise = torch.randn(img.shape[0], self.hparams.latent_dim, 1, 1)\n",
        "\n",
        "            self.generated_img = self(noise)\n",
        "            self.generated_img = self.AddGaussianNoise(self.generated_img) # Add noise for a better distribution\n",
        "\n",
        "            valid_lbl = (0.8 - 1.1) * torch.rand(img.shape[0], 1) + 1.1  # soft labels\n",
        "\n",
        "            g_loss = self.binary_cross_entropy(self.discriminator(self.generated_img), valid_lbl)\n",
        "\n",
        "            tqdm_dict = {'g_loss': g_loss}\n",
        "            logs = {\"g_loss\": g_loss}\n",
        "            return {\"loss\": g_loss, \"log\": logs, 'progress_bar': tqdm_dict}\n",
        "\n",
        "        # Train Discriminator\n",
        "        if optimizer_idx == 1:\n",
        "            valid_lbl = (0.8 - 1.1) * torch.rand(img.shape[0], 1) + 1.1  # soft labels\n",
        "            unvalid_lbl = (0.0 - 0.3) * torch.rand(img.shape[0], 1) + 0.3  # soft labels\n",
        "\n",
        "            d_loss = 0\n",
        "\n",
        "            # Experience replay\n",
        "            perm = torch.randperm(self.generated_img.size(0))  # Shuffeling\n",
        "            r_idx = perm[:max(1, self.hparams.experience_save_per_batch)]  # Getting the index\n",
        "            self.exp_replay = torch.cat((self.exp_replay, self.generated_img[r_idx]),\n",
        "                                        0).detach()  # Add our new example to the replay buffer\n",
        "\n",
        "            if self.exp_replay.size(0) >= self.hparams.experience_batch_size:  # when we have enough example from the past train on them\n",
        "                unvalid_lbl = (0.0 - 0.3) * torch.rand(self.exp_replay.shape[0], 1) + 0.3  # soft labels\n",
        "                fake_loss = self.binary_cross_entropy(self.discriminator(self.exp_replay), unvalid_lbl)\n",
        "\n",
        "                d_loss = fake_loss\n",
        "                self.exp_replay = torch.tensor([])\n",
        "\n",
        "            else:\n",
        "                real_loss = self.binary_cross_entropy(self.discriminator(img), valid_lbl)\n",
        "\n",
        "                fake_loss = self.binary_cross_entropy(self.discriminator(self.generated_img.detach()), unvalid_lbl)\n",
        "\n",
        "                d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "            tqdm_dict = {'d_loss': d_loss}\n",
        "            logs = {\"d_loss\": d_loss}\n",
        "            return {\"loss\": d_loss, \"log\": logs, 'progress_bar': tqdm_dict}\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=self.hparams.lr,\n",
        "                                 betas=(self.hparams.b1, self.hparams.b2))\n",
        "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=self.hparams.lr,\n",
        "                                 betas=(self.hparams.b1, self.hparams.b2))\n",
        "\n",
        "        return opt_g, opt_d\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        transform = transforms.Compose([transforms.Resize((256, 256)),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize([0.5], [0.5]),\n",
        "                                       # AddGaussianNoise()\n",
        "                                        ])\n",
        "        \n",
        "        train_dataset = torchvision.datasets.ImageFolder(\n",
        "            root=\"./drive/My Drive/datasets/\",\n",
        "            transform=transform\n",
        "        )\n",
        "        return DataLoader(train_dataset, num_workers=3, batch_size=self.hparams.batch_size, shuffle=True)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        noise = torch.randn(4, self.hparams.latent_dim, 1, 1)\n",
        "\n",
        "        sample_img = self.generator(noise)\n",
        "        sample_img = sample_img.view(-1, 3, 256, 256)\n",
        "        grid = torchvision.utils.make_grid(sample_img, nrow=2).permute(1, 2, 0)\n",
        "        comet_logger.experiment.log_image(grid, f'generated_images_epoch{self.current_epoch}', step=self.current_epoch)\n",
        "\n",
        "        if self.current_epoch % self.hparams.save_model_every_epoch == 0:\n",
        "            trainer.save_checkpoint(\n",
        "                checkpoint_folder + \"/\" + experiment_name + \"_epoch_\" + str(self.current_epoch) + \".ckpt\")\n",
        "            comet_logger.experiment.log_asset_folder(checkpoint_folder)\n",
        "\n",
        "            if dirpath.exists() and dirpath.is_dir():\n",
        "                shutil.rmtree(dirpath)\n",
        "\n",
        "            # creating checkpoint folder\n",
        "            access_rights = 0o755\n",
        "            os.makedirs(checkpoint_folder, access_rights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeJ2llxkdgtG"
      },
      "source": [
        "# Parameters\n",
        "experiment_name = \"GHIBLI_DCGAN_V1\"\n",
        "dataset_name = \"GHIBLI\"\n",
        "checkpoint_folder = \"DCGAN/\"\n",
        "tags = [\"DCGAN\", \"GHIBLI\"]\n",
        "dirpath = Path(checkpoint_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbByyaEFdgvf"
      },
      "source": [
        "# Hyperparameters\n",
        "from argparse import Namespace\n",
        "\n",
        "args = {\n",
        "    'batch_size': 10,\n",
        "    'lr': 0.0002,\n",
        "    'b1': 0.5,\n",
        "    'b2': 0.999,\n",
        "    'latent_dim': 150,\n",
        "    'level_of_noise': 0.1,\n",
        "    'epochs': 20,\n",
        "    'ndf': 64,\n",
        "    'ngf': 64,\n",
        "    'experience_batch_size': 20,\n",
        "    'experience_save_per_batch': 2,\n",
        "    'save_model_every_epoch': 300,\n",
        "    'nc': 3\n",
        "}\n",
        "\n",
        "hparams = Namespace(**args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIDi0Hq_eB_W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6243c029-c802-43b2-e936-5e80543957b4"
      },
      "source": [
        "# init logger\n",
        "comet_logger = loggers.CometLogger(\n",
        "    api_key=\"\",\n",
        "    rest_api_key=\"\",\n",
        "    project_name=\"GAN\",\n",
        "    experiment_name=experiment_name,\n",
        ")\n",
        "\n",
        "#defining net\n",
        "net = DCGAN(hparams)\n",
        "\n",
        "#logging\n",
        "comet_logger.experiment.set_model_graph(str(net))\n",
        "comet_logger.experiment.add_tags(tags=tags)\n",
        "comet_logger.experiment.log_dataset_info(dataset_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:lightning:CometLogger will be initialized in online mode\n",
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/luposx/gan/7a814cad52054ceab0ae6785560e63cc\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikxqwj9keCCA"
      },
      "source": [
        "# deleting the checkpoint folder\n",
        "if dirpath.exists() and dirpath.is_dir():\n",
        "    shutil.rmtree(dirpath)\n",
        " \n",
        "# creating checkpoint folder\n",
        "access_rights = 0o755\n",
        "os.makedirs(checkpoint_folder, access_rights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUeHAFR7eFAI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "55b3317418144d22ad41ddfc94ae7a98",
            "227683ee024f4eb8975c2c68e75d1fc3",
            "433eabe9eb1c4f44acca630d22e84be9",
            "946d6f46cb204b1a80d3825bc926ba88",
            "03488427d3954a9f8169cd652dc52c9c",
            "bd72cc1a1df847ae85f402526ccc321a",
            "d845f448d37b47a1ac3f52f51d8d4c6f",
            "b5b9ebc9161a42eaa47da2779209e486"
          ]
        },
        "outputId": "2208bcca-5714-4734-c56e-7a4c5b5464ab"
      },
      "source": [
        "# Start training\n",
        "\n",
        "trainer = pl.Trainer(# resume_from_checkpoint=checkpoint_folder + \"/MNIST_GAN_V2_epoch2.ckpt\",\n",
        "                     logger=comet_logger,\n",
        "                     max_epochs=args[\"epochs\"]\n",
        "                     )    \n",
        "trainer.fit(net)\n",
        "trainer.save_checkpoint(checkpoint_folder + \"/\" + experiment_name + \"_epoch_\" + str(args[\"epochs\"]) + \".ckpt\")\n",
        "comet_logger.experiment.log_asset_folder(checkpoint_folder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:lightning:\n",
            "   | Name                | Type            | Params\n",
            "----------------------------------------------------\n",
            "0  | generator           | Generator       | 862 K \n",
            "1  | generator.fc1       | Sequential      | 524 K \n",
            "2  | generator.fc1.0     | ConvTranspose2d | 524 K \n",
            "3  | generator.fc1.1     | LeakyReLU       | 0     \n",
            "4  | generator.fc2       | Sequential      | 196 K \n",
            "5  | generator.fc2.0     | ConvTranspose2d | 196 K \n",
            "6  | generator.fc2.1     | LeakyReLU       | 0     \n",
            "7  | generator.fc3       | Sequential      | 98 K  \n",
            "8  | generator.fc3.0     | ConvTranspose2d | 98 K  \n",
            "9  | generator.fc3.1     | LeakyReLU       | 0     \n",
            "10 | generator.fc4       | Sequential      | 32 K  \n",
            "11 | generator.fc4.0     | ConvTranspose2d | 32 K  \n",
            "12 | generator.fc4.1     | LeakyReLU       | 0     \n",
            "13 | generator.fc5       | Sequential      | 8 K   \n",
            "14 | generator.fc5.0     | ConvTranspose2d | 8 K   \n",
            "15 | generator.fc5.1     | LeakyReLU       | 0     \n",
            "16 | generator.fc6       | Sequential      | 2 K   \n",
            "17 | generator.fc6.0     | ConvTranspose2d | 2 K   \n",
            "18 | generator.fc6.1     | LeakyReLU       | 0     \n",
            "19 | generator.fc7       | Sequential      | 384   \n",
            "20 | generator.fc7.0     | ConvTranspose2d | 384   \n",
            "21 | generator.fc7.1     | Tanh            | 0     \n",
            "22 | discriminator       | Discriminator   | 6 M   \n",
            "23 | discriminator.fc1   | Sequential      | 3 K   \n",
            "24 | discriminator.fc1.0 | Conv2d          | 3 K   \n",
            "25 | discriminator.fc1.1 | LeakyReLU       | 0     \n",
            "26 | discriminator.fc2   | Sequential      | 131 K \n",
            "27 | discriminator.fc2.0 | Conv2d          | 131 K \n",
            "28 | discriminator.fc2.1 | LeakyReLU       | 0     \n",
            "29 | discriminator.fc3   | Sequential      | 524 K \n",
            "30 | discriminator.fc3.0 | Conv2d          | 524 K \n",
            "31 | discriminator.fc3.1 | LeakyReLU       | 0     \n",
            "32 | discriminator.fc4   | Sequential      | 2 M   \n",
            "33 | discriminator.fc4.0 | Conv2d          | 2 M   \n",
            "34 | discriminator.fc4.1 | LeakyReLU       | 0     \n",
            "35 | discriminator.fc5   | Sequential      | 3 M   \n",
            "36 | discriminator.fc5.0 | Conv2d          | 3 M   \n",
            "37 | discriminator.fc5.1 | LeakyReLU       | 0     \n",
            "38 | discriminator.fc6   | Sequential      | 786 K \n",
            "39 | discriminator.fc6.0 | Conv2d          | 786 K \n",
            "40 | discriminator.fc6.1 | LeakyReLU       | 0     \n",
            "41 | discriminator.fc7   | Sequential      | 2 K   \n",
            "42 | discriminator.fc7.0 | Conv2d          | 2 K   \n",
            "43 | discriminator.fc7.1 | Sigmoid         | 0     \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55b3317418144d22ad41ddfc94ae7a98",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/warnings.py:18: RuntimeWarning: Displayed epoch numbers in the progress bar start from \"1\" until v0.6.x, but will start from \"0\" in v0.8.0.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32, 1, 1, 1])) is deprecated. Please ensure they have the same size.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Using a target size (torch.Size([7, 1])) that is different to the input size (torch.Size([7, 1, 1, 1])) is deprecated. Please ensure they have the same size.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200, 1, 1, 1])) is deprecated. Please ensure they have the same size.\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.comet.ml', port=443): Read timed out. (read timeout=10)\",)': /clientlib/status-report/update\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.comet.ml', port=443): Read timed out. (read timeout=10)\",)': /clientlib/status-report/update\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.comet.ml', port=443): Read timed out. (read timeout=10)\",)': /clientlib/status-report/update\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.comet.ml', port=443): Read timed out. (read timeout=10)\",)': /clientlib/status-report/update\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.comet.ml', port=443): Read timed out. (read timeout=10)\",)': /clientlib/status-report/update\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.comet.ml', port=443): Read timed out. (read timeout=10)\",)': /clientlib/status-report/update\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.comet.ml', port=443): Read timed out. (read timeout=10)\",)': /clientlib/status-report/update\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.comet.ml', port=443): Read timed out. (read timeout=10)\",)': /clientlib/status-report/update\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}