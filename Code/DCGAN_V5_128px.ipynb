{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN_V5_128px.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a7b17fa2a2fb48d98a1f29c8fb369f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3bbcd32a3df3416b922d6d66afc5b71b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4ad417d8e7bf4b25a5dfc4b314bea623",
              "IPY_MODEL_af860ea271914ccba93bb98a20481715"
            ]
          }
        },
        "3bbcd32a3df3416b922d6d66afc5b71b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "4ad417d8e7bf4b25a5dfc4b314bea623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f076c7c547194d56b05db60b1d4499da",
            "_dom_classes": [],
            "description": "Epoch 5000: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07015f0bc2354ea181b9ea7adc06732a"
          }
        },
        "af860ea271914ccba93bb98a20481715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4dc76ab3bfd14e30b148bb36be85c0fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00,  1.46it/s, d_loss=0.407, g_loss=1.71, loss=1.044, v_num=df8a0e79360643eaac79ec198aee6229]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16f75bd3f08040319d4463d37c46f7d4"
          }
        },
        "f076c7c547194d56b05db60b1d4499da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07015f0bc2354ea181b9ea7adc06732a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4dc76ab3bfd14e30b148bb36be85c0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16f75bd3f08040319d4463d37c46f7d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8X_1iB5lmFK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "adf08c82-886b-4f5f-adb3-5e92a8277240"
      },
      "source": [
        "!pip install comet_ml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: comet_ml in /usr/local/lib/python3.6/dist-packages (3.1.6)\n",
            "Requirement already satisfied: everett[ini]>=1.0.1; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (3.7.4.2)\n",
            "Requirement already satisfied: comet-git-pure>=0.19.11 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.19.16)\n",
            "Requirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.57.0)\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.6.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.21.0)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.0.0)\n",
            "Requirement already satisfied: netifaces>=0.10.7 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.10.9)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (7.352.0)\n",
            "Requirement already satisfied: configobj; extra == \"ini\" in /usr/local/lib/python3.6/dist-packages (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet_ml) (5.0.6)\n",
            "Requirement already satisfied: urllib3>=1.24.1 in /usr/local/lib/python3.6/dist-packages (from comet-git-pure>=0.19.11->comet_ml) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from comet-git-pure>=0.19.11->comet_ml) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9YRNLuvhdbA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "e24f5d68-a979-43c5-c633-fbdbd16db3dd"
      },
      "source": [
        "!pip install pytorch_lightning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.6/dist-packages (0.7.3)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (0.18.2)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (1.4.0)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (2.2.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (4.45.0)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (1.18.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (0.4.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (0.34.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.12.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (2.21.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.6.0.post3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.28.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (46.1.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.7.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (3.2.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (3.10.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbcdihZOlqRl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "5fa55da4-1c28-4e40-cf02-2c364fb56f62"
      },
      "source": [
        "# used fo TPU\n",
        "# Uncomment if you want to use TPU\n",
        "# ------------------------------------------------------------------\n",
        "import collections\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import requests\n",
        "import threading\n",
        "\n",
        "_VersionConfig = collections.namedtuple('_VersionConfig', 'wheels,server')\n",
        "VERSION = \"xrt==1.15.0\"  #@param [\"xrt==1.15.0\", \"torch_xla==nightly\"]\n",
        "CONFIG = {\n",
        "    'xrt==1.15.0': _VersionConfig('1.15', '1.15.0'),\n",
        "    'torch_xla==nightly': _VersionConfig('nightly', 'XRT-dev{}'.format(\n",
        "        (datetime.today() - timedelta(1)).strftime('%Y%m%d'))),\n",
        "}[VERSION]\n",
        "DIST_BUCKET = 'gs://tpu-pytorch/wheels'\n",
        "TORCH_WHEEL = 'torch-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
        "TORCH_XLA_WHEEL = 'torch_xla-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
        "TORCHVISION_WHEEL = 'torchvision-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
        "\n",
        "# Update TPU XRT version\n",
        "def update_server_xrt():\n",
        "  print('Updating server-side XRT to {} ...'.format(CONFIG.server))\n",
        "  url = 'http://{TPU_ADDRESS}:8475/requestversion/{XRT_VERSION}'.format(\n",
        "      TPU_ADDRESS=os.environ['COLAB_TPU_ADDR'].split(':')[0],\n",
        "      XRT_VERSION=CONFIG.server,\n",
        "  )\n",
        "  print('Done updating server-side XRT: {}'.format(requests.post(url)))\n",
        "\n",
        "update = threading.Thread(target=update_server_xrt)\n",
        "update.start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating server-side XRT to 1.15.0 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-4:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-3-947a1487c49e>\", line 23, in update_server_xrt\n",
            "    TPU_ADDRESS=os.environ['COLAB_TPU_ADDR'].split(':')[0],\n",
            "  File \"/usr/lib/python3.6/os.py\", line 669, in __getitem__\n",
            "    raise KeyError(key) from None\n",
            "KeyError: 'COLAB_TPU_ADDR'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5Pdwezwlxrk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f53839b0-c658-4de6-f7e8-5225b6d2a7f7"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision  \n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import loggers\n",
        "\n",
        "import numpy as np\n",
        "from numpy.random import choice\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from skimage import transform as sktransform\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "from collections import OrderedDict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmsPuzKgdqbU"
      },
      "source": [
        "# lets hope this fixes the bug that my pc crashes after reconnecting\n",
        "from IPython.display import clear_output "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB4Sais-leap"
      },
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU0SxP6LsoSc"
      },
      "source": [
        "# randomly flip some labels\n",
        "def noisy_labels(y, p_flip=0.05):  # # flip labels with 5% probability\n",
        "\t# determine the number of labels to flip\n",
        "\tn_select = int(p_flip * y.shape[0])\n",
        "\t# choose labels to flip\n",
        "\tflip_ix = choice([i for i in range(y.shape[0])], size=n_select)\n",
        "\t# invert the labels in place\n",
        "\ty[flip_ix] = 1 - y[flip_ix]\n",
        "\treturn y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndGu3Fsr5pK7"
      },
      "source": [
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0.0, std=0.1):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_Xv6CtcHLwA"
      },
      "source": [
        "def resize2d(img, size):\n",
        "    return (F.adaptive_avg_pool2d(Variable(img,volatile=True), size)).data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE1NiIkWgZl1"
      },
      "source": [
        "def get_valid_labels(img):\n",
        "  return (0.8 - 1.1) * torch.rand(img.shape[0], 1, 1, 1) + 1.1  # soft labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEwvU2CJgarz"
      },
      "source": [
        "def get_unvalid_labels(img):\n",
        "  return noisy_labels((0.0 - 0.3) * torch.rand(img.shape[0], 1, 1, 1) + 0.3)  # soft labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdkoz4Qslzta"
      },
      "source": [
        "class Generator(pl.LightningModule):\n",
        "    def __init__(self, ngf, nc, latent_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngf = ngf\n",
        "        self.latent_dim = latent_dim\n",
        "        self.nc = nc\n",
        "\n",
        "        self.fc0 = nn.Sequential(\n",
        "             # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d(latent_dim, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Sequential(\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.fc2 = nn.Sequential(\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.fc3 = nn.Sequential(\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.fc4 = nn.Sequential(\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.fc5 = nn.Sequential(\n",
        "            # state size. (nc) x 64 x 64\n",
        "            nn.ConvTranspose2d(nc, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # state size. (nc) x 128 x 128\n",
        "\n",
        "        # For Multi-Scale Gradient\n",
        "        # Converting the intermediate layers into images\n",
        "        self.fc0_r = nn.Conv2d(ngf * 8, self.nc, 1)\n",
        "        self.fc1_r = nn.Conv2d(ngf * 4, self.nc, 1)\n",
        "        self.fc2_r = nn.Conv2d(ngf * 2, self.nc, 1)\n",
        "        self.fc3_r = nn.Conv2d(self.ngf, self.nc, 1)\n",
        "        self.fc4_r = nn.Conv2d(self.ngf, self.nc, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x_0 = self.fc0(input)\n",
        "        x_1 = self.fc1(x_0)\n",
        "        x_2 = self.fc2(x_1)\n",
        "        x_3 = self.fc3(x_2)\n",
        "        x_4 = self.fc4(x_3)\n",
        "        x_5 = self.fc4(x_4)\n",
        "\n",
        "        # For Multi-Scale Gradient\n",
        "        # Converting the intermediate layers into images\n",
        "        x_0_r = self.fc0_r(x_0)\n",
        "        x_1_r = self.fc1_r(x_1)\n",
        "        x_2_r = self.fc2_r(x_2)\n",
        "        x_3_r = self.fc3_r(x_3)\n",
        "        x_4_r = self.fc3_r(x_4)\n",
        "\n",
        "        return x_4, x_0_r, x_1_r, x_2_r, x_3_r, x_4_r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ShwAUX4meZa"
      },
      "source": [
        "class Discriminator(pl.LightningModule):\n",
        "    def __init__(self, ndf, nc):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.nc = nc\n",
        "        self.ndf = ndf\n",
        "\n",
        "        self.fc0 = nn.Sequential(\n",
        "            # input is (nc) x 128 x 128\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Sequential(\n",
        "            # state size. (ndf) x 64 x 64\n",
        "            nn.Conv2d(ndf + 3, ndf * 2, 4, 2, 1, bias=False),  # \"+ 3\" because of multi scale gradient\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.fc2 = nn.Sequential(\n",
        "            # state size. (ndf*2) x 32 x 32\n",
        "            nn.Conv2d(ndf * 2 + 3, ndf * 4, 4, 2, 1, bias=False), # \"+ 3\" because of multi scale gradient\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.fc3 = nn.Sequential(\n",
        "            # state size. (ndf*4) x 16 x 16\n",
        "            nn.Conv2d(ndf * 4 + 3, ndf * 8, 4, 2, 1, bias=False), # \"+ 3\" because of multi scale gradient\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.fc4 = nn.Sequential(\n",
        "            # state size. (ndf*8) x 8 x 8\n",
        "            nn.Conv2d(ndf * 8 + 3, ndf, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.fc5 = nn.Sequential(\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(ndf + 3, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # state size. 1 x 1 x 1\n",
        "\n",
        "    def forward(self, input, detach_or_not):\n",
        "        # When we train i ncombination with generator we use multi scale gradient.\n",
        "        x_4, x_0_r, x_1_r, x_2_r, x_3_r, x_4_r = input\n",
        "        if detach_or_not:\n",
        "            x_4 = x_4.detach()\n",
        "\n",
        "        x_0 = self.fc0(x_4)\n",
        "\n",
        "        x_0 = torch.cat((x_0, x_4_r), dim=1)  # Concat Multi-Scale Gradient\n",
        "        x_1 = self.fc1(x_0)\n",
        "\n",
        "        x_1 = torch.cat((x_1, x_3_r), dim=1)  # Concat Multi-Scale Gradient\n",
        "        x_2 = self.fc2(x_1)\n",
        "\n",
        "        x_2 = torch.cat((x_2, x_2_r), dim=1)  # Concat Multi-Scale Gradient\n",
        "        x_3 = self.fc3(x_2)\n",
        "\n",
        "        x_3 = torch.cat((x_3, x_1_r), dim=1)  # Concat Multi-Scale Gradient\n",
        "        x_4 = self.fc4(x_3)\n",
        "\n",
        "        x_4 = torch.cat((x_4, x_0_r), dim=1)  # Concat Multi-Scale Gradient\n",
        "        x_5 = self.fc5(x_4)\n",
        "\n",
        "        return x_4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrG2sRBdmtub"
      },
      "source": [
        "class DCGAN(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, hparams, logger, checkpoint_folder, experiment_name):\n",
        "        super().__init__()\n",
        "        self.hparams = hparams\n",
        "        self.logger = logger  # only compatible with comet_logger at the moment\n",
        "        self.checkpoint_folder = checkpoint_folder\n",
        "        self.experiment_name = experiment_name\n",
        "\n",
        "        # networks\n",
        "        self.generator = Generator(ngf=hparams.ngf, nc=hparams.nc, latent_dim=hparams.latent_dim)\n",
        "        self.discriminator = Discriminator(ndf=hparams.ndf, nc=hparams.nc)\n",
        "        self.generator.apply(weights_init)\n",
        "        self.discriminator.apply(weights_init)\n",
        "\n",
        "        # cache for generated images\n",
        "        self.generated_imgs = None\n",
        "        self.last_imgs = None\n",
        "\n",
        "        # For experience replay\n",
        "        self.exp_replay_dis = torch.tensor([])\n",
        "\n",
        "        # creating checkpoint folder\n",
        "        dirpath = Path(self.checkpoint_folder)\n",
        "        if not dirpath.exists():\n",
        "            os.makedirs(dirpath, 0o755)\n",
        "        \n",
        "        # For multipel-gradient\n",
        "        self.trans4 = transforms.Resize((4, 4))\n",
        "        self.trans8 = transforms.Resize((8, 8))\n",
        "        self.trans16 = transforms.Resize((16, 16))\n",
        "        self.trans32 = transforms.Resize((32, 32))\n",
        "        self.transPil = transforms.ToPILImage()\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.generator(z)\n",
        "\n",
        "    def adversarial_loss(self, y_hat, y):\n",
        "        return F.binary_cross_entropy(y_hat, y)\n",
        "\n",
        "    def training_step(self, batch, batch_nb, optimizer_idx):\n",
        "\n",
        "        # For adding Instance noise for more visit: https://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/\n",
        "        std_gaussian = max(0, self.hparams.level_of_noise - (\n",
        "                    (self.hparams.level_of_noise * 2) * (self.current_epoch / self.hparams.epochs)))\n",
        "        AddGaussianNoiseInst = AddGaussianNoise(std=std_gaussian)  # the noise decays over time\n",
        "\n",
        "        imgs, _ = batch\n",
        "        imgs = AddGaussianNoiseInst(imgs)  # Adding instance noise to real images\n",
        "        self.last_imgs = imgs\n",
        "\n",
        "        # train generator\n",
        "        if optimizer_idx == 0:\n",
        "            # sample noise\n",
        "            z = torch.randn(imgs.shape[0], self.hparams.latent_dim, 1, 1)\n",
        "\n",
        "            # generate images\n",
        "            self.generated_imgs = self(z)\n",
        "\n",
        "            # ground truth result (ie: all fake)\n",
        "            g_loss = self.adversarial_loss(self.discriminator(self.generated_imgs, False), get_valid_labels(\n",
        "                self.generated_imgs[0]))  # adversarial loss is binary cross-entropy; [0] is the image of the last layer\n",
        "\n",
        "            tqdm_dict = {'g_loss': g_loss}\n",
        "            log = {'g_loss': g_loss, \"std_gaussian\": std_gaussian}\n",
        "            output = OrderedDict({\n",
        "                'loss': g_loss,\n",
        "                'progress_bar': tqdm_dict,\n",
        "                'log': log\n",
        "            })\n",
        "            return output\n",
        "\n",
        "        # train discriminator\n",
        "        if optimizer_idx == 1:\n",
        "            # Measure discriminator's ability to classify real from generated samples\n",
        "            # how well can it label as real?\n",
        "            real_loss = self.adversarial_loss(self.discriminator([imgs, resize2d(imgs, 4), resize2d(imgs, 8), resize2d(imgs, 16), resize2d(imgs, 32)], False), get_valid_labels(imgs))\n",
        "\n",
        "            fake_loss = self.adversarial_loss(self.discriminator(self.generated_imgs, True), get_unvalid_labels(\n",
        "                self.generated_imgs[0]))  # how well can it label as fake?; [0] is the image of the last layer\n",
        "\n",
        "            # discriminator loss is the average of these\n",
        "            d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "            tqdm_dict = {'d_loss': d_loss}\n",
        "            log = {'d_loss': d_loss, \"std_gaussian\": std_gaussian}\n",
        "            output = OrderedDict({\n",
        "                'loss': d_loss,\n",
        "                'progress_bar': tqdm_dict,\n",
        "                'log': log\n",
        "            })\n",
        "            return output\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        lr_gen = self.hparams.lr_gen\n",
        "        lr_dis = self.hparams.lr_dis\n",
        "        b1 = self.hparams.b1\n",
        "        b2 = self.hparams.b2\n",
        "\n",
        "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr_gen, betas=(b1, b2))\n",
        "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr_dis, betas=(b1, b2))\n",
        "        return [opt_g, opt_d], []\n",
        "\n",
        "    def backward(self, trainer, loss, optimizer, optimizer_idx: int) -> None:\n",
        "        loss.backward(retain_graph=True)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        # transform = transforms.Compose([transforms.Resize((self.hparams.image_size, self.hparams.image_size)),\n",
        "        #                                 transforms.ToTensor(),\n",
        "        #                                 transforms.Normalize([0.5], [0.5])])\n",
        "        # dataset = MNIST(os.getcwd(), train=True, download=True, transform=transform)\n",
        "        # return DataLoader(dataset, batch_size=self.hparams.batch_size)\n",
        "        # transform = transforms.Compose([transforms.Resize((self.hparams.image_size, self.hparams.image_size)),\n",
        "        #                                 transforms.ToTensor(),\n",
        "        #                                 transforms.Normalize([0.5], [0.5])\n",
        "        #                                 ])\n",
        "\n",
        "        # train_dataset = torchvision.datasets.ImageFolder(\n",
        "        #     # root=\"./drive/My Drive/datasets/flower_dataset/\",\n",
        "        #     root=\"./drive/My Drive/datasets/ghibli_dataset_small_overfit/\",\n",
        "        #     transform=transform\n",
        "        # )\n",
        "        # return DataLoader(train_dataset, num_workers=self.hparams.num_workers, shuffle=True,\n",
        "        #                   batch_size=self.hparams.batch_size)\n",
        "        transform = transforms.Compose([transforms.Resize((self.hparams.image_size, self.hparams.image_size)),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize([0.5], [0.5])\n",
        "                                        ])\n",
        "\n",
        "        train_dataset = torchvision.datasets.ImageFolder(\n",
        "            root=\"./drive/My Drive/datasets/flower_dataset_miscrosoft/flower_dataset/\",\n",
        "            transform=transform\n",
        "        )\n",
        "        return DataLoader(train_dataset, num_workers=self.hparams.num_workers, shuffle=True, batch_size=self.hparams.batch_size)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        z = torch.randn(4, self.hparams.latent_dim, 1, 1)\n",
        "        # match gpu device (or keep as cpu)\n",
        "        if self.on_gpu:\n",
        "            z = z.cuda(self.last_imgs.device.index)\n",
        "\n",
        "        # log sampled images\n",
        "        sample_imgs = self.generator(z)[0]\n",
        "        sample_imgs = sample_imgs.view(-1, self.hparams.nc, self.hparams.image_size, self.hparams.image_size)\n",
        "        grid = torchvision.utils.make_grid(sample_imgs, nrow=2)\n",
        "        self.logger.experiment.log_image(grid.permute(1, 2, 0), f'generated_images_epoch{self.current_epoch}',\n",
        "                                         step=self.current_epoch)\n",
        "\n",
        "        # save model\n",
        "        if self.current_epoch % self.hparams.save_model_every_epoch == 0:\n",
        "            trainer.save_checkpoint(\n",
        "                self.checkpoint_folder + \"/\" + self.experiment_name + \"_epoch_\" + str(self.current_epoch) + \".ckpt\")\n",
        "            comet_logger.experiment.log_asset_folder(self.checkpoint_folder, step=self.current_epoch)\n",
        "\n",
        "            # Deleting the folder where we saved the model so that we dont upload a thing twice\n",
        "            dirpath = Path(self.checkpoint_folder)\n",
        "            if dirpath.exists() and dirpath.is_dir():\n",
        "                shutil.rmtree(dirpath)\n",
        "\n",
        "            # creating checkpoint folder\n",
        "            access_rights = 0o755\n",
        "            os.makedirs(dirpath, access_rights)\n",
        "\n",
        "    def on_train_end(self):\n",
        "        trainer.save_checkpoint(\n",
        "            self.checkpoint_folder + \"/\" + self.experiment_name + \"_epoch_\" + str(self.current_epoch) + \".ckpt\")\n",
        "        comet_logger.experiment.log_asset_folder(self.checkpoint_folder, step=self.current_epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P93AorTGoLLy"
      },
      "source": [
        "from argparse import Namespace\n",
        "\n",
        "args = {\n",
        "    'batch_size': 32,\n",
        "    'lr_gen': 0.0003, # TTUR;learnin rate of both networks; tested value: 0.0002\n",
        "    'lr_dis': 0.0003, # TTUR;learnin rate of both networks; tested value: 0.0002\n",
        "    'b1': 0.5, # Momentum for adam; tested value(dcgan paper): 0.5\n",
        "    'b2': 0.999, # Momentum for adam; tested value(dcgan paper): 0.999\n",
        "    'latent_dim': 256, # tested value which worked(in V4_1): 100\n",
        "    'nc': 3, # number of color channels\n",
        "    'ndf': 32, # number of discriminator features\n",
        "    'ngf': 32, # number of generator features\n",
        "    'epochs': 5000, # the maxima lamount of epochs the algorith should run\n",
        "    'save_model_every_epoch': 1000, # how often we save our model\n",
        "    'image_size': 128,\n",
        "    'num_workers': 3,\n",
        "    'level_of_noise': 0.5,  # how much instance noise we introduce(std; tested value: 0.15 and 0.1\n",
        "    'experience_save_per_batch': 1, # this value should be very low; tested value which works: 1\n",
        "    'experience_batch_size': 50 # this value shouldnt be too high; tested value which works: 50\n",
        "}\n",
        "hparams = Namespace(**args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GASBvFhToTYm"
      },
      "source": [
        "# Parameters\n",
        "experiment_name = \"DCGAN_V5_2\"\n",
        "dataset_name = \"Mnist\"\n",
        "checkpoint_folder = \"DCGAN/\"\n",
        "tags = [\"DCGAN\", \"GHIBLI\", \"OVERFIT\", \"64x64\"]\n",
        "dirpath = Path(checkpoint_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S1UWfyboc-0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f4295fd7-c103-4ad6-d84b-5aa4e52d1c78"
      },
      "source": [
        "# init logger\n",
        "comet_logger = loggers.CometLogger(\n",
        "    api_key=\"\",\n",
        "    rest_api_key=\"\",\n",
        "    project_name=\"gan-testing-models\",\n",
        "    experiment_name=experiment_name,\n",
        "    # experiment_key=\"222a685177474cb9b358b5ee642564dc\"  # used for resuming trained id can be found in comet.ml\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:lightning:CometLogger will be initialized in online mode\n",
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/luposx/gan-testing-models/df8a0e79360643eaac79ec198aee6229\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejR3uYGcogKI"
      },
      "source": [
        "#defining net\n",
        "net = DCGAN(hparams, comet_logger, checkpoint_folder, experiment_name)\n",
        "\n",
        "#logging\n",
        "comet_logger.experiment.set_model_graph(str(net))\n",
        "comet_logger.experiment.add_tags(tags=tags)\n",
        "comet_logger.experiment.log_dataset_info(dataset_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13TGWtbCom6S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221,
          "referenced_widgets": [
            "a7b17fa2a2fb48d98a1f29c8fb369f40",
            "3bbcd32a3df3416b922d6d66afc5b71b",
            "4ad417d8e7bf4b25a5dfc4b314bea623",
            "af860ea271914ccba93bb98a20481715",
            "f076c7c547194d56b05db60b1d4499da",
            "07015f0bc2354ea181b9ea7adc06732a",
            "4dc76ab3bfd14e30b148bb36be85c0fe",
            "16f75bd3f08040319d4463d37c46f7d4"
          ]
        },
        "outputId": "1ae54699-c0d1-4b9c-fe4b-df4938d725e9"
      },
      "source": [
        "clear_output(wait=True)\n",
        "\n",
        "trainer = pl.Trainer(# resume_from_checkpoint=\"DCGAN_V4_2_GHIBLI_epoch_999.ckpt\",\n",
        "                     logger=comet_logger, \n",
        "                     max_epochs=args[\"epochs\"]\n",
        "                     )\n",
        "\n",
        "clear_output(wait=True)\n",
        "\n",
        "trainer.fit(net)\n",
        "\n",
        "clear_output(wait=True)\n",
        "comet_logger.experiment.end()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/luposx/gan-testing-models/df8a0e79360643eaac79ec198aee6229\n",
            "\n",
            "COMET INFO: -----------------------------------\n",
            "COMET INFO: Comet.ml ExistingExperiment Summary\n",
            "COMET INFO: -----------------------------------\n",
            "COMET INFO:   Data:\n",
            "COMET INFO:     display_summary_level : 1\n",
            "COMET INFO:     url                   : https://www.comet.ml/luposx/gan-testing-models/df8a0e79360643eaac79ec198aee6229\n",
            "COMET INFO: -----------------------------------\n",
            "COMET INFO: Uploading stats to Comet before program termination (may take several seconds)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}