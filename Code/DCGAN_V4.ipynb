{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN_V4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a5f900e5df184dff9735de2ac7030b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_49e04c7feb4f4c65a76650a4de2b547a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5e3122504164471f9f02c5f869c43931",
              "IPY_MODEL_14150ecdcffa49518dcc1919523995b3"
            ]
          }
        },
        "49e04c7feb4f4c65a76650a4de2b547a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "5e3122504164471f9f02c5f869c43931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_abda42f00fa84498a4e01957fea0ce4b",
            "_dom_classes": [],
            "description": "Epoch 50: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 129,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 129,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ddb7b0b20b1d411991d4e4b57c26d95c"
          }
        },
        "14150ecdcffa49518dcc1919523995b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f366191c77044028b808dda6ae8894c3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 129/129 [09:12&lt;00:00,  4.28s/it, d_loss=0.651, g_loss=2.35, loss=0.943, v_num=b57c14480b134d97a0daa42e79c65629]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57aa7be05a6443579471eb6082129d24"
          }
        },
        "abda42f00fa84498a4e01957fea0ce4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ddb7b0b20b1d411991d4e4b57c26d95c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f366191c77044028b808dda6ae8894c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57aa7be05a6443579471eb6082129d24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "05lNj69G4C9x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "af21afe6-2d55-4ebc-da09-4b73f80c0ebc"
      },
      "source": [
        "!pip install comet_ml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: comet_ml in /usr/local/lib/python3.6/dist-packages (3.1.6)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (7.352.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.12.0)\n",
            "Requirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.57.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (3.7.4.2)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.0.0)\n",
            "Requirement already satisfied: everett[ini]>=1.0.1; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.0.2)\n",
            "Requirement already satisfied: comet-git-pure>=0.19.11 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.19.16)\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.6.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.21.0)\n",
            "Requirement already satisfied: netifaces>=0.10.7 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.10.9)\n",
            "Requirement already satisfied: configobj; extra == \"ini\" in /usr/local/lib/python3.6/dist-packages (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet_ml) (5.0.6)\n",
            "Requirement already satisfied: urllib3>=1.24.1 in /usr/local/lib/python3.6/dist-packages (from comet-git-pure>=0.19.11->comet_ml) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from comet-git-pure>=0.19.11->comet_ml) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (2.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGd-GNKl4OF_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "f49fc335-f9c1-4783-df40-7d2a22f77355"
      },
      "source": [
        "!pip install pytorch_lightning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.6/dist-packages (0.7.3)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (1.18.2)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (4.45.0)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (1.4.0)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (2.2.1)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (0.18.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (3.2.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.28.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (3.10.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.6.0.post3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (2.21.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (0.9.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (46.1.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.7.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (0.4.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (0.34.2)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (2020.4.5.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-RjB9Wn4TSN"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision  \n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import loggers\n",
        "\n",
        "import numpy as np\n",
        "from numpy.random import choice\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "from collections import OrderedDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9AEjAib4VHl"
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5xQ_nc04Xae"
      },
      "source": [
        "def noisy_labels(y, p_flip=0.05):  # # flip labels with 5% probability\n",
        "\t# determine the number of labels to flip\n",
        "\tn_select = int(p_flip * y.shape[0])\n",
        "\t# choose labels to flip\n",
        "\tflip_ix = choice([i for i in range(y.shape[0])], size=n_select)\n",
        "\t# invert the labels in place\n",
        "\ty[flip_ix] = 1 - y[flip_ix]\n",
        "\treturn y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp7FHTGA4Y2H"
      },
      "source": [
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0.0, std=0.1):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2PQkmSz4bNP"
      },
      "source": [
        "def get_valid_labels(img):\n",
        "  return (0.8 - 1.1) * torch.rand(img.shape[0], 1, 1, 1) + 1.1  # soft labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSg9Hdvy4dK6"
      },
      "source": [
        "def get_unvalid_labels(img):\n",
        "  return noisy_labels((0.0 - 0.3) * torch.rand(img.shape[0], 1, 1, 1) + 0.3)  # soft labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g52Zv-wN4gV5"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngf, nc, latent_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngf = ngf\n",
        "        self.latent_dim = latent_dim\n",
        "        self.nc = nc\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d(latent_dim, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (nc) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFszNXii4ibh"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ndf, nc):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.nc = nc\n",
        "        self.ndf = ndf\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            # input is (nc) x 64 x 64\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izwcXyx94lfk"
      },
      "source": [
        "class DCGAN(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, hparams, logger, checkpoint_folder, experiment_name):\n",
        "        super().__init__()\n",
        "        self.hparams = hparams\n",
        "        self.logger = logger  # only compatible with comet_logger at the moment\n",
        "        self.checkpoint_folder = checkpoint_folder\n",
        "        self.experiment_name = experiment_name\n",
        "\n",
        "        # networks\n",
        "        self.generator = Generator(ngf=hparams.ngf, nc=hparams.nc, latent_dim=hparams.latent_dim)\n",
        "        self.discriminator = Discriminator(ndf=hparams.ndf, nc=hparams.nc)\n",
        "        self.generator.apply(weights_init)\n",
        "        self.discriminator.apply(weights_init)\n",
        "\n",
        "        # cache for generated images\n",
        "        self.generated_imgs = None\n",
        "        self.last_imgs = None\n",
        "\n",
        "        # For experience replay\n",
        "        self.exp_replay_dis = torch.tensor([])\n",
        "\n",
        "        # creating checkpoint folder\n",
        "        dirpath = Path(self.checkpoint_folder)\n",
        "        if not dirpath.exists():\n",
        "          os.makedirs(dirpath, 0o755)\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.generator(z)\n",
        "\n",
        "    def adversarial_loss(self, y_hat, y):\n",
        "        return F.binary_cross_entropy(y_hat, y)\n",
        "\n",
        "    def training_step(self, batch, batch_nb, optimizer_idx):\n",
        "        # For adding Instance noise for more visit: https://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/\n",
        "        std_gaussian = max(0, self.hparams.level_of_noise - ((self.hparams.level_of_noise * 1.5) * (self.current_epoch / self.hparams.epochs)))\n",
        "        AddGaussianNoiseInst = AddGaussianNoise(std=std_gaussian) # the noise decays over time\n",
        "\n",
        "        imgs, _ = batch\n",
        "        imgs = AddGaussianNoiseInst(imgs) # Adding instance noise to real images\n",
        "        self.last_imgs = imgs\n",
        "\n",
        "        # train generator\n",
        "        if optimizer_idx == 0:\n",
        "            # sample noise\n",
        "            z = torch.randn(imgs.shape[0], self.hparams.latent_dim, 1, 1)\n",
        "\n",
        "            # generate images\n",
        "            self.generated_imgs = self(z)\n",
        "            self.generated_imgs = AddGaussianNoiseInst(self.generated_imgs) # Adding instance noise to fake images\n",
        "\n",
        "            # Experience replay\n",
        "            # for discriminator\n",
        "            perm = torch.randperm(self.generated_imgs.size(0))  # Shuffeling\n",
        "            r_idx = perm[:max(1, self.hparams.experience_save_per_batch)]  # Getting the index\n",
        "            self.exp_replay_dis = torch.cat((self.exp_replay_dis, self.generated_imgs[r_idx]), 0).detach()  # Add our new example to the replay buffer\n",
        "\n",
        "            # ground truth result (ie: all fake)\n",
        "            g_loss = self.adversarial_loss(self.discriminator(self.generated_imgs), get_valid_labels(self.generated_imgs)) # adversarial loss is binary cross-entropy\n",
        "\n",
        "            tqdm_dict = {'g_loss': g_loss}\n",
        "            log = {'g_loss': g_loss, \"std_gaussian\": std_gaussian}\n",
        "            output = OrderedDict({\n",
        "                'loss': g_loss,\n",
        "                'progress_bar': tqdm_dict,\n",
        "                'log': log\n",
        "            })\n",
        "            return output\n",
        "\n",
        "        # train discriminator\n",
        "        if optimizer_idx == 1:\n",
        "            # Measure discriminator's ability to classify real from generated samples\n",
        "            # how well can it label as real?\n",
        "            real_loss = self.adversarial_loss(self.discriminator(imgs), get_valid_labels(imgs))\n",
        "\n",
        "            # Experience replay\n",
        "            if self.exp_replay_dis.size(0) >= self.hparams.experience_batch_size:\n",
        "              fake_loss = self.adversarial_loss(self.discriminator(self.exp_replay_dis.detach()), get_unvalid_labels(self.exp_replay_dis))  # train on already seen images\n",
        "\n",
        "              self.exp_replay_dis = torch.tensor([]) # Reset experience replay\n",
        "\n",
        "              # discriminator loss is the average of these\n",
        "              d_loss = (real_loss + fake_loss) / 2\n",
        "              \n",
        "              tqdm_dict = {'d_loss': d_loss}\n",
        "              log = {'d_loss': d_loss, \"d_exp_loss\": fake_loss, \"std_gaussian\": std_gaussian}\n",
        "              output = OrderedDict({\n",
        "                  'loss': d_loss,\n",
        "                  'progress_bar': tqdm_dict,\n",
        "                  'log': log\n",
        "              })\n",
        "              return output\n",
        "\n",
        "            else:\n",
        "              fake_loss = self.adversarial_loss(self.discriminator(self.generated_imgs.detach()), get_unvalid_labels(self.generated_imgs))  # how well can it label as fake?\n",
        "\n",
        "              # discriminator loss is the average of these\n",
        "              d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "              tqdm_dict = {'d_loss': d_loss}\n",
        "              log = {'d_loss': d_loss, \"std_gaussian\": std_gaussian}\n",
        "              output = OrderedDict({\n",
        "                  'loss': d_loss,\n",
        "                  'progress_bar': tqdm_dict,\n",
        "                  'log': log\n",
        "              })\n",
        "              return output\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        lr = self.hparams.lr\n",
        "        b1 = self.hparams.b1\n",
        "        b2 = self.hparams.b2\n",
        "\n",
        "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=(b1, b2))\n",
        "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
        "        return [opt_g, opt_d], []\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        # transform = transforms.Compose([transforms.ToTensor(),\n",
        "        #                                 transforms.Normalize([0.5], [0.5])])\n",
        "        # dataset = MNIST(os.getcwd(), train=True, download=True, transform=transform)\n",
        "        # return DataLoader(dataset, batch_size=self.hparams.batch_size)\n",
        "        transform = transforms.Compose([transforms.Resize((self.hparams.image_size, self.hparams.image_size)),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize([0.5], [0.5])\n",
        "                                        ])\n",
        "\n",
        "        train_dataset = torchvision.datasets.ImageFolder(\n",
        "            root=\"./drive/My Drive/datasets/flower_dataset_miscrosoft/flower_dataset/\",\n",
        "            transform=transform\n",
        "        )\n",
        "        return DataLoader(train_dataset, num_workers=self.hparams.num_workers, shuffle=True, batch_size=self.hparams.batch_size)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        z = torch.randn(4, self.hparams.latent_dim, 1, 1)\n",
        "        # match gpu device (or keep as cpu)\n",
        "        if self.on_gpu:\n",
        "            z = z.cuda(self.last_imgs.device.index)\n",
        "\n",
        "        # log sampled images\n",
        "        sample_imgs = self.generator(z)\n",
        "        sample_imgs = sample_imgs.view(-1, self.hparams.nc, self.hparams.image_size, self.hparams.image_size)\n",
        "        grid = torchvision.utils.make_grid(sample_imgs, nrow=2)\n",
        "        self.logger.experiment.log_image(grid.permute(1, 2, 0), f'generated_images_epoch{self.current_epoch}', step=self.current_epoch)\n",
        "\n",
        "        # save model\n",
        "        if self.current_epoch % self.hparams.save_model_every_epoch == 0:\n",
        "          trainer.save_checkpoint(self.checkpoint_folder + \"/\" + self.experiment_name + \"_epoch_\" + str(self.current_epoch) + \".ckpt\")\n",
        "          comet_logger.experiment.log_asset_folder(self.checkpoint_folder, step=self.current_epoch)\n",
        "\n",
        "          # Deleting the folder where we saved the model so that we dont upload a thing twice\n",
        "          dirpath = Path(self.checkpoint_folder)\n",
        "          if dirpath.exists() and dirpath.is_dir():\n",
        "                shutil.rmtree(dirpath)\n",
        "\n",
        "          # creating checkpoint folder\n",
        "          access_rights = 0o755\n",
        "          os.makedirs(dirpath, access_rights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyySfPtl4y7O"
      },
      "source": [
        "from argparse import Namespace\n",
        "\n",
        "args = {\n",
        "    'batch_size': 64,\n",
        "    'lr': 0.0002,\n",
        "    'b1': 0.5,\n",
        "    'b2': 0.999,\n",
        "    'latent_dim': 256,\n",
        "    'nc': 3,\n",
        "    'ndf': 64,\n",
        "    'ngf': 64,\n",
        "    'epochs': 50,\n",
        "    'save_model_every_epoch': 2,\n",
        "    'image_size': 64,\n",
        "    'num_workers': 3,\n",
        "    'level_of_noise': 0.00,\n",
        "    'experience_save_per_batch': 1,\n",
        "    'experience_batch_size': 50\n",
        "}\n",
        "hparams = Namespace(**args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptx7da5m41CW"
      },
      "source": [
        "experiment_name = \"DCGAN_V4_flower\"\n",
        "dataset_name = \"GHIBLI_OVERFIT\"\n",
        "checkpoint_folder = \"DCGAN/\"\n",
        "tags = [\"DCGAN\", \"GHIBLI\", \"OVERFIT\", \"64x64\"]\n",
        "dirpath = Path(checkpoint_folder)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7JJNpYs426x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "bf727fd6-19f8-42c1-e1b0-9650c31c8d04"
      },
      "source": [
        "comet_logger = loggers.CometLogger(\n",
        "    api_key=\"\",\n",
        "    rest_api_key=\"\",\n",
        "    project_name=\"gan\",\n",
        "    experiment_name=experiment_name,\n",
        "    experiment_key=\"b57c14480b134d97a0daa42e79c65629\"  # used for resuming trained id can be found in comet.ml\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:lightning:CometLogger will be initialized in online mode\n",
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/luposx/gan/b57c14480b134d97a0daa42e79c65629\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McXgYijj440I"
      },
      "source": [
        "net = DCGAN(hparams, comet_logger, checkpoint_folder, experiment_name)\n",
        "\n",
        "#logging\n",
        "comet_logger.experiment.set_model_graph(str(net))\n",
        "comet_logger.experiment.add_tags(tags=tags)\n",
        "comet_logger.experiment.log_dataset_info(dataset_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRB5ZFQO46zR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a5f900e5df184dff9735de2ac7030b96",
            "49e04c7feb4f4c65a76650a4de2b547a",
            "5e3122504164471f9f02c5f869c43931",
            "14150ecdcffa49518dcc1919523995b3",
            "abda42f00fa84498a4e01957fea0ce4b",
            "ddb7b0b20b1d411991d4e4b57c26d95c",
            "f366191c77044028b808dda6ae8894c3",
            "57aa7be05a6443579471eb6082129d24"
          ]
        },
        "outputId": "fc12dd30-65ea-4413-bb04-e6f0513ba2b7"
      },
      "source": [
        "trainer = pl.Trainer(resume_from_checkpoint=\"DCGAN_V4_flower_epoch_24.ckpt\",\n",
        "                     logger=comet_logger,\n",
        "                     max_epochs=args[\"epochs\"]\n",
        "                     )\n",
        "trainer.fit(net)\n",
        "comet_logger.experiment.end()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:lightning:\n",
            "   | Name                  | Type            | Params\n",
            "------------------------------------------------------\n",
            "0  | generator             | Generator       | 4 M   \n",
            "1  | generator.main        | Sequential      | 4 M   \n",
            "2  | generator.main.0      | ConvTranspose2d | 2 M   \n",
            "3  | generator.main.1      | BatchNorm2d     | 1 K   \n",
            "4  | generator.main.2      | LeakyReLU       | 0     \n",
            "5  | generator.main.3      | ConvTranspose2d | 2 M   \n",
            "6  | generator.main.4      | BatchNorm2d     | 512   \n",
            "7  | generator.main.5      | LeakyReLU       | 0     \n",
            "8  | generator.main.6      | ConvTranspose2d | 524 K \n",
            "9  | generator.main.7      | BatchNorm2d     | 256   \n",
            "10 | generator.main.8      | LeakyReLU       | 0     \n",
            "11 | generator.main.9      | ConvTranspose2d | 131 K \n",
            "12 | generator.main.10     | BatchNorm2d     | 128   \n",
            "13 | generator.main.11     | LeakyReLU       | 0     \n",
            "14 | generator.main.12     | ConvTranspose2d | 3 K   \n",
            "15 | generator.main.13     | Tanh            | 0     \n",
            "16 | discriminator         | Discriminator   | 2 M   \n",
            "17 | discriminator.main    | Sequential      | 2 M   \n",
            "18 | discriminator.main.0  | Conv2d          | 3 K   \n",
            "19 | discriminator.main.1  | LeakyReLU       | 0     \n",
            "20 | discriminator.main.2  | Conv2d          | 131 K \n",
            "21 | discriminator.main.3  | BatchNorm2d     | 256   \n",
            "22 | discriminator.main.4  | LeakyReLU       | 0     \n",
            "23 | discriminator.main.5  | Conv2d          | 524 K \n",
            "24 | discriminator.main.6  | BatchNorm2d     | 512   \n",
            "25 | discriminator.main.7  | LeakyReLU       | 0     \n",
            "26 | discriminator.main.8  | Conv2d          | 2 M   \n",
            "27 | discriminator.main.9  | BatchNorm2d     | 1 K   \n",
            "28 | discriminator.main.10 | LeakyReLU       | 0     \n",
            "29 | discriminator.main.11 | Conv2d          | 8 K   \n",
            "30 | discriminator.main.12 | Sigmoid         | 0     \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5f900e5df184dff9735de2ac7030b96",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/warnings.py:18: RuntimeWarning: Displayed epoch numbers in the progress bar start from \"1\" until v0.6.x, but will start from \"0\" in v0.8.0.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.comet.ml', port=443): Read timed out. (read timeout=10)\",)': /clientlib/status-report/update\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.comet.ml', port=443): Read timed out. (read timeout=10)\",)': /clientlib/status-report/update\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.comet.ml', port=443): Read timed out. (read timeout=10)\",)': /clientlib/status-report/update\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.comet.ml', port=443): Read timed out. (read timeout=10)\",)': /clientlib/status-report/update\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.comet.ml', port=443): Read timed out. (read timeout=10)\",)': /clientlib/status-report/update\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.comet.ml', port=443): Read timed out. (read timeout=10)\",)': /clientlib/status-report/update\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.comet.ml', port=443): Read timed out. (read timeout=10)\",)': /clientlib/status-report/update\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.comet.ml', port=443): Read timed out. (read timeout=10)\",)': /clientlib/status-report/update\n",
            "COMET INFO: -----------------------------------\n",
            "COMET INFO: Comet.ml ExistingExperiment Summary\n",
            "COMET INFO: -----------------------------------\n",
            "COMET INFO:   Data:\n",
            "COMET INFO:     display_summary_level : 1\n",
            "COMET INFO:     url                   : https://www.comet.ml/luposx/gan/b57c14480b134d97a0daa42e79c65629\n",
            "COMET INFO:   Metrics [count] (min, max):\n",
            "COMET INFO:     d_exp_loss [7]     : (0.5084680318832397, 0.8346386551856995)\n",
            "COMET INFO:     d_loss [324]       : (0.3794284462928772, 1.2694746255874634)\n",
            "COMET INFO:     g_loss [324]       : (0.2086424082517624, 2.94638729095459)\n",
            "COMET INFO:     std_gaussian [324] : (0, 0.0075)\n",
            "COMET INFO:   Others:\n",
            "COMET INFO:     Name         : DCGAN_V4_flower\n",
            "COMET INFO:     dataset_info : GHIBLI_OVERFIT\n",
            "COMET INFO:   Parameters:\n",
            "COMET INFO:     b1                        : 0.5\n",
            "COMET INFO:     b2                        : 0.999\n",
            "COMET INFO:     batch_size                : 64\n",
            "COMET INFO:     epochs                    : 50\n",
            "COMET INFO:     experience_batch_size     : 50\n",
            "COMET INFO:     experience_save_per_batch : 1\n",
            "COMET INFO:     image_size                : 64\n",
            "COMET INFO:     latent_dim                : 256\n",
            "COMET INFO:     level_of_noise            : 0.03\n",
            "COMET INFO:     lr                        : 0.0002\n",
            "COMET INFO:     nc                        : 3\n",
            "COMET INFO:     ndf                       : 64\n",
            "COMET INFO:     ngf                       : 64\n",
            "COMET INFO:     num_workers               : 3\n",
            "COMET INFO:     save_model_every_epoch    : 2\n",
            "COMET INFO:   Uploads [count]:\n",
            "COMET INFO:     asset [12]  : 12\n",
            "COMET INFO:     images [25] : 25\n",
            "COMET INFO:     model graph : 1\n",
            "COMET INFO: -----------------------------------\n",
            "COMET INFO: Uploading stats to Comet before program termination (may take several seconds)\n",
            "COMET INFO: Waiting for completion of the file uploads (may take several seconds)\n",
            "COMET INFO: Still uploading\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/luposx/gan/b57c14480b134d97a0daa42e79c65629\n",
            "\n",
            "COMET INFO: -----------------------------------\n",
            "COMET INFO: Comet.ml ExistingExperiment Summary\n",
            "COMET INFO: -----------------------------------\n",
            "COMET INFO:   Data:\n",
            "COMET INFO:     display_summary_level : 1\n",
            "COMET INFO:     url                   : https://www.comet.ml/luposx/gan/b57c14480b134d97a0daa42e79c65629\n",
            "COMET INFO: -----------------------------------\n",
            "COMET INFO: Uploading stats to Comet before program termination (may take several seconds)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTltdfWc5BXA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}