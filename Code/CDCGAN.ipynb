{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CDCGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGgMGHO6ZTaT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "69183ae3-9b58-41e0-8ffb-92ec1f181977"
      },
      "source": [
        "!pip install pytorch_lightning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.6/dist-packages (0.7.2)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (1.18.2)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (2.2.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (4.45.0)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (0.18.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (46.1.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (2.21.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (3.10.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.7.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (0.4.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.27.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.6.0.post2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (0.9.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (3.2.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (0.34.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf9GjSjJZrDv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "0cbaaa55-73b9-464f-eb2c-4035a683223a"
      },
      "source": [
        "!pip install comet_ml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: comet_ml in /usr/local/lib/python3.6/dist-packages (3.1.4)\n",
            "Requirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.57.0)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (7.352.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.21.0)\n",
            "Requirement already satisfied: netifaces>=0.10.7 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.10.9)\n",
            "Requirement already satisfied: comet-git-pure>=0.19.11 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.19.15)\n",
            "Requirement already satisfied: everett[ini]>=1.0.1; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.12.0)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.0.0)\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (3.7.4.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (2019.11.28)\n",
            "Requirement already satisfied: configobj; extra == \"ini\" in /usr/local/lib/python3.6/dist-packages (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet_ml) (5.0.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxkqtVXYZrGm"
      },
      "source": [
        "# used fo TPU\n",
        "# Uncomment if you want to use TPU\n",
        "# import collections\n",
        "# from datetime import datetime, timedelta\n",
        "# import os\n",
        "# import requests\n",
        "# import threading\n",
        "\n",
        "# _VersionConfig = collections.namedtuple('_VersionConfig', 'wheels,server')\n",
        "# VERSION = \"xrt==1.15.0\"  #@param [\"xrt==1.15.0\", \"torch_xla==nightly\"]\n",
        "# CONFIG = {\n",
        "#     'xrt==1.15.0': _VersionConfig('1.15', '1.15.0'),\n",
        "#     'torch_xla==nightly': _VersionConfig('nightly', 'XRT-dev{}'.format(\n",
        "#         (datetime.today() - timedelta(1)).strftime('%Y%m%d'))),\n",
        "# }[VERSION]\n",
        "# DIST_BUCKET = 'gs://tpu-pytorch/wheels'\n",
        "# TORCH_WHEEL = 'torch-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
        "# TORCH_XLA_WHEEL = 'torch_xla-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
        "# TORCHVISION_WHEEL = 'torchvision-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
        "\n",
        "# # Update TPU XRT version\n",
        "# def update_server_xrt():\n",
        "#   print('Updating server-side XRT to {} ...'.format(CONFIG.server))\n",
        "#   url = 'http://{TPU_ADDRESS}:8475/requestversion/{XRT_VERSION}'.format(\n",
        "#       TPU_ADDRESS=os.environ['COLAB_TPU_ADDR'].split(':')[0],\n",
        "#       XRT_VERSION=CONFIG.server,\n",
        "#   )\n",
        "#   print('Done updating server-side XRT: {}'.format(requests.post(url)))\n",
        "\n",
        "# update = threading.Thread(target=update_server_xrt)\n",
        "#update.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbRd17X7ZrJP"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import loggers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwqo75WEZrLu"
      },
      "source": [
        "class Discriminator(pl.LightningModule):\n",
        "  def __init__(self, ndf):\n",
        "      super().__init__()\n",
        "      self.ndf = ndf\n",
        "\n",
        "      self.condi = nn.Sequential(\n",
        "            nn.Linear(in_features=10, out_features=32 * 32)\n",
        "        )\n",
        "      self.fc1 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=2, out_channels=self.ndf, kernel_size=4, stride=2, padding=1, bias=False),  # 2 in channels because of condition\n",
        "          nn.LeakyReLU(0.2)\n",
        "      )\n",
        "      self.fc2 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=self.ndf, out_channels=self.ndf * 2, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "          nn.LeakyReLU(0.2)\n",
        "      )\n",
        "      self.fc3 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=self.ndf * 2, out_channels=self.ndf * 3, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "          nn.LeakyReLU(0.2)\n",
        "      )\n",
        "      self.fc4 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=self.ndf * 3, out_channels=self.ndf * 6, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "          torch.nn.Sigmoid()\n",
        "      )\n",
        "      self.fc5 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=self.ndf * 6, out_channels=1, kernel_size=3, stride=2, padding=1,bias=False),\n",
        "          nn.Sigmoid()\n",
        "      )\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    y = get_hot_vector_encode(y).detach()\n",
        "    y = self.condi(y.view(-1, 10))\n",
        "    y = y.view(-1, 1, 32, 32)\n",
        "    \n",
        "    x_cond = torch.cat((x, y), dim=1)\n",
        "\n",
        "    x = self.fc1(x_cond)\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "    x = self.fc4(x)\n",
        "    x = self.fc5(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMMPHvVoZrOK"
      },
      "source": [
        "class Generator(pl.LightningModule):\n",
        "  def __init__(self, latent_dim, ngf):\n",
        "    super().__init__()\n",
        "    self.ngf = 16\n",
        "    self.n_features = latent_dim\n",
        "\n",
        "    self.fc1 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels=self.n_features + 10, out_channels=self.ngf * 8, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "    self.fc2 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(self.ngf * 8, self.ngf * 4, 4, 2, 1, False),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "    self.fc3 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(self.ngf * 4, self.ngf * 2, 4, 2, 1, False),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "    self.fc4 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(self.ngf * 2, self.ngf, 4, 2, 1, False),\n",
        "          nn.LeakyReLU(0.2)\n",
        "    )\n",
        "    self.fc5 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels=self.ngf, out_channels=1, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "          nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    y = get_hot_vector_encode(y).detach()\n",
        "    x_cond = torch.cat((x, y), dim=1)\n",
        "\n",
        "    x = self.fc1(x_cond)\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "    x = self.fc4(x)\n",
        "    x = self.fc5(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvwXuKuzZyNw"
      },
      "source": [
        "class DCGAN(pl.LightningModule):\n",
        "  def __init__(self, hparams):\n",
        "    super().__init__()\n",
        "    self.hparams = hparams\n",
        "\n",
        "    self.generator = Generator(hparams.latent_dim, hparams.ngf)\n",
        "    self.discriminator = Discriminator(hparams.ndf)\n",
        "\n",
        "    # cache for generated images\n",
        "    self.generated_imgs = None\n",
        "    self.last_imgs = None\n",
        "\n",
        "    # For experience replay\n",
        "    self.exp_replay = torch.tensor([])\n",
        "    self.exp_replay_labels = torch.tensor([], dtype=torch.long)\n",
        "\n",
        "  def binary_cross_entropy(self, y_hat, y):\n",
        "    return F.binary_cross_entropy(y_hat, y)\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    return self.generator(x, y)\n",
        "  \n",
        "  def training_step(self, batch, batch_nb, optimizer_idx):\n",
        "    img, labels = batch\n",
        "    self.last_imgs = img\n",
        "\n",
        "    # Train Generator\n",
        "    if optimizer_idx == 0:\n",
        "      noise = torch.randn(img.shape[0], self.hparams.latent_dim, 1, 1)\n",
        "\n",
        "      self.generated_img = self(noise, labels)\n",
        "\n",
        "      valid_lbl = (0.8 - 1.1) * torch.rand(img.shape[0], 1) + 1.1  # soft labels\n",
        "\n",
        "      g_loss = self.binary_cross_entropy(self.discriminator(self.generated_img, labels), valid_lbl)\n",
        "      \n",
        "      tqdm_dict = {'g_loss': g_loss}\n",
        "      logs = {\"g_loss\": g_loss}\n",
        "      return {\"loss\": g_loss, \"log\": logs, 'progress_bar': tqdm_dict}\n",
        "\n",
        "    # Train Discriminator\n",
        "    if optimizer_idx == 1:\n",
        "      valid_lbl = (0.8 - 1.1) * torch.rand(img.shape[0], 1) + 1.1  # soft labels\n",
        "      unvalid_lbl = (0.0 - 0.3) * torch.rand(img.shape[0], 1) + 0.3  # soft labels\n",
        "\n",
        "      # Experience replay\n",
        "      r_idx = max(1, self.hparams.experience_save_per_batch) # Getting the index\n",
        "      self.exp_replay = torch.cat((self.exp_replay, self.generated_img[r_idx]), 0).detach() # Add our new example to the replay buffer\n",
        "      \n",
        "      self.exp_replay_labels = torch.cat((self.exp_replay_labels, labels[r_idx].unsqueeze(dim=0))).detach() # Add new labels to the replay buffer\n",
        "\n",
        "      if self.exp_replay.size(0) >= self.hparams.experience_batch_size: # when we have enough example from the past train on them\n",
        "         print(\"Experience replay epoch\")\n",
        "         \n",
        "         self.exp_replay = self.exp_replay.unsqueeze(dim=1)\n",
        "         unvalid_lbl = (0.0 - 0.3) * torch.rand(self.exp_replay.shape[0], 1) + 0.3  # soft labels\n",
        "         fake_loss = self.binary_cross_entropy(self.discriminator(self.exp_replay, self.exp_replay_labels), unvalid_lbl)\n",
        "         \n",
        "         d_loss = fake_loss\n",
        "         self.exp_replay = torch.tensor([])\n",
        "         self.exp_replay_labels = torch.tensor([], dtype=torch.long)\n",
        "\n",
        "      else:\n",
        "        real_loss = self.binary_cross_entropy(self.discriminator(img, labels), valid_lbl)\n",
        "\n",
        "        fake_loss = self.binary_cross_entropy(self.discriminator(self.generated_img.detach(), labels), unvalid_lbl)\n",
        "        \n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "      tqdm_dict = {'d_loss': d_loss}\n",
        "      logs = {\"d_loss\": d_loss}\n",
        "      return {\"loss\": d_loss, \"log\": logs, 'progress_bar': tqdm_dict}\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    opt_g = torch.optim.Adam(self.generator.parameters(), lr=self.hparams.lr, betas=(self.hparams.b1, self.hparams.b2))\n",
        "    opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=self.hparams.lr, betas=(self.hparams.b1, self.hparams.b2))\n",
        "\n",
        "    return opt_g, opt_d\n",
        "    \n",
        "  def train_dataloader(self):\n",
        "    transform = transforms.Compose([transforms.Resize((32, 32)),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize([0.5], [0.5])])\n",
        "    dataset = MNIST(os.getcwd(), train=True, download=True, transform=transform)\n",
        "    return DataLoader(dataset, num_workers=self.hparams.num_workers, batch_size=self.hparams.batch_size)\n",
        "    \n",
        "  def on_epoch_end(self):\n",
        "      noise = torch.randn(4, self.hparams.latent_dim, 1, 1)\n",
        "\n",
        "      sample_img = self.generator(noise, torch.tensor((4, 6, 7, 1)))\n",
        "      sample_img = sample_img.view(-1, 1, 32, 32)\n",
        "      grid = torchvision.utils.make_grid(sample_img, nrow=2).permute(1, 2, 0)\n",
        "      comet_logger.experiment.log_image(grid, f'generated_images_epoch{self.current_epoch}', step=self.current_epoch)\n",
        "\n",
        "      if self.current_epoch % 5 == 0:\n",
        "        trainer.save_checkpoint(checkpoint_folder + \"/\" + experiment_name + \"_epoch_\" + str(self.current_epoch) + \".ckpt\")\n",
        "        comet_logger.experiment.log_asset_folder(checkpoint_folder)\n",
        "\n",
        "        if dirpath.exists() and dirpath.is_dir():\n",
        "            shutil.rmtree(dirpath)\n",
        "\n",
        "        # creating checkpoint folder\n",
        "        access_rights = 0o755\n",
        "        os.makedirs(checkpoint_folder, access_rights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M76s8ECmImBD"
      },
      "source": [
        "def get_hot_vector_encode(labels):\n",
        "    return torch.eye(10)[labels].view(-1, 10, 1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SZ-grwKZyQt"
      },
      "source": [
        "# Parameters\n",
        "experiment_name = \"MNIST_CDCGAN_V1\"\n",
        "dataset_name = \"MNIST\"\n",
        "checkpoint_folder = \"CDCGAN/\"\n",
        "tags = [\"CDCGAN\", \"MNIST\"]\n",
        "dirpath = Path(checkpoint_folder) # for saving checkpoints "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCwp6ipZe3QU"
      },
      "source": [
        "# Hyperparameters\n",
        "from argparse import Namespace\n",
        "\n",
        "args = {\n",
        "    'batch_size': 64,\n",
        "    'lr': 0.0002,\n",
        "    'b1': 0.5,\n",
        "    'b2': 0.999,\n",
        "    'latent_dim': 128,\n",
        "    'level_of_noise': 0.1,\n",
        "    'epochs': 100,\n",
        "    'r_frequent': 100,\n",
        "    'ndf': 16,\n",
        "    'ngf': 16,\n",
        "    'num_workers': 3,\n",
        "    'experience_batch_size': 2000,\n",
        "    'experience_save_per_batch': 1,\n",
        "}\n",
        "\n",
        "hparams = Namespace(**args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw2BogQrZyTa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "78e05fd1-a888-4eda-e35f-36bea4a6c0ad"
      },
      "source": [
        "# init logger\n",
        "comet_logger = loggers.CometLogger(\n",
        "    api_key=\"\",\n",
        "    rest_api_key=\"\",\n",
        "    project_name=\"GAN\",\n",
        "    experiment_name=experiment_name,\n",
        ")\n",
        "\n",
        "#defining net\n",
        "net = DCGAN(hparams)\n",
        "\n",
        "#logging\n",
        "comet_logger.experiment.set_model_graph(str(net))\n",
        "comet_logger.experiment.add_tags(tags=tags)\n",
        "comet_logger.experiment.log_dataset_info(dataset_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:lightning:CometLogger will be initialized in online mode\n",
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/luposx/gan/84f9a601dd6c4f6d9481ba83a8cd5970\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKMeq0NogNEi"
      },
      "source": [
        "# deleting the checkpoint folder\n",
        "if dirpath.exists() and dirpath.is_dir():\n",
        "    shutil.rmtree(dirpath)\n",
        " \n",
        "# creating checkpoint folder\n",
        "access_rights = 0o755\n",
        "os.makedirs(checkpoint_folder, access_rights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XIJS0xUZ1wC"
      },
      "source": [
        "# Start training\n",
        "\n",
        "trainer = pl.Trainer(# resume_from_checkpoint=checkpoint_folder + \"/MNIST_GAN_V2_epoch2.ckpt\",\n",
        "                     logger=comet_logger,\n",
        "                     max_epochs=args[\"epochs\"]\n",
        "                     )    \n",
        "trainer.fit(net)\n",
        "trainer.save_checkpoint(checkpoint_folder + \"/\" + experiment_name + \"_epoch_\" + str(args[\"epochs\"]) + \".ckpt\")\n",
        "comet_logger.experiment.log_asset_folder(checkpoint_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0UoOhmcbqvf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}