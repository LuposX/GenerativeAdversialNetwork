{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN_GHIBLI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "579e5a9ef6ef4678a9b0a0fa89634555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_55ca991857024119aebfdf49f2b7f637",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1b3defa8f2b34bdcbce4fdfcf2b1d254",
              "IPY_MODEL_74bd43ba14f2477c8d8595bfc06339f6"
            ]
          }
        },
        "55ca991857024119aebfdf49f2b7f637": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "1b3defa8f2b34bdcbce4fdfcf2b1d254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0393545ac63d4070a924b9ceae6f7e80",
            "_dom_classes": [],
            "description": "Epoch 8792:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb43ce96d8af4988a904a36154bc6bf4"
          }
        },
        "74bd43ba14f2477c8d8595bfc06339f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_433ee25860b645e180a2f6d5ecf0cc5d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/1 [00:00&lt;?, ?it/s, d_loss=0.267, g_loss=1.81, loss=1.098, v_num=8ed4bf0b88ab4e9594a001439c653b99]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3b0c3392e2254346979fda24b9f16a0e"
          }
        },
        "0393545ac63d4070a924b9ceae6f7e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb43ce96d8af4988a904a36154bc6bf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "433ee25860b645e180a2f6d5ecf0cc5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3b0c3392e2254346979fda24b9f16a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8c7zqVhAdtR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "cc6b4cb5-91b0-4fbd-e81d-e417b63b389e"
      },
      "source": [
        "!pip install pytorch_lightning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.6/dist-packages (0.7.3)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (1.4.0)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (2.2.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (4.45.0)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (1.18.2)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (0.18.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.6.0.post3)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (0.34.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (3.2.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.7.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (46.1.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (0.4.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.28.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (0.9.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (2.21.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.12.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E9l276JAdhH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "c3668ab0-e3e5-4096-efe2-f38aec9f415d"
      },
      "source": [
        "!pip install comet_ml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: comet_ml in /usr/local/lib/python3.6/dist-packages (3.1.4)\n",
            "Requirement already satisfied: comet-git-pure>=0.19.11 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.19.15)\n",
            "Requirement already satisfied: everett[ini]>=1.0.1; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.0.2)\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.6.0)\n",
            "Requirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.57.0)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.12.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.21.0)\n",
            "Requirement already satisfied: netifaces>=0.10.7 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.10.9)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (7.352.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (3.7.4.2)\n",
            "Requirement already satisfied: urllib3>=1.24.1 in /usr/local/lib/python3.6/dist-packages (from comet-git-pure>=0.19.11->comet_ml) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from comet-git-pure>=0.19.11->comet_ml) (2020.4.5.1)\n",
            "Requirement already satisfied: configobj; extra == \"ini\" in /usr/local/lib/python3.6/dist-packages (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet_ml) (5.0.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (2.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi3nssz2AtlG"
      },
      "source": [
        "# used fo TPU\n",
        "# Uncomment if you want to use TPU\n",
        "# import collections\n",
        "# from datetime import datetime, timedelta\n",
        "# import os\n",
        "# import requests\n",
        "# import threading\n",
        "\n",
        "# _VersionConfig = collections.namedtuple('_VersionConfig', 'wheels,server')\n",
        "# VERSION = \"xrt==1.15.0\"  #@param [\"xrt==1.15.0\", \"torch_xla==nightly\"]\n",
        "# CONFIG = {\n",
        "#     'xrt==1.15.0': _VersionConfig('1.15', '1.15.0'),\n",
        "#     'torch_xla==nightly': _VersionConfig('nightly', 'XRT-dev{}'.format(\n",
        "#         (datetime.today() - timedelta(1)).strftime('%Y%m%d'))),\n",
        "# }[VERSION]\n",
        "# DIST_BUCKET = 'gs://tpu-pytorch/wheels'\n",
        "# TORCH_WHEEL = 'torch-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
        "# TORCH_XLA_WHEEL = 'torch_xla-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
        "# TORCHVISION_WHEEL = 'torchvision-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
        "\n",
        "# # Update TPU XRT version\n",
        "# def update_server_xrt():\n",
        "#   print('Updating server-side XRT to {} ...'.format(CONFIG.server))\n",
        "#   url = 'http://{TPU_ADDRESS}:8475/requestversion/{XRT_VERSION}'.format(\n",
        "#       TPU_ADDRESS=os.environ['COLAB_TPU_ADDR'].split(':')[0],\n",
        "#       XRT_VERSION=CONFIG.server,\n",
        "#   )\n",
        "#   print('Done updating server-side XRT: {}'.format(requests.post(url)))\n",
        "\n",
        "# update = threading.Thread(target=update_server_xrt)\n",
        "#update.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf9RgKAN_1uC"
      },
      "source": [
        "import numpy as np\n",
        "from numpy.random import choice\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision  \n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import loggers\n",
        "\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZIKlRWLn4Mp"
      },
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C0TTfBt_6uP"
      },
      "source": [
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0.0, std=0.1):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwB4epK-KwRt"
      },
      "source": [
        "# randomly flip some labels\n",
        "def noisy_labels(y, p_flip=0.05):  # # flip labels with 5% probability\n",
        "\t# determine the number of labels to flip\n",
        "\tn_select = int(p_flip * y.shape[0])\n",
        "\t# choose labels to flip\n",
        "\tflip_ix = choice([i for i in range(y.shape[0])], size=n_select)\n",
        "\t# invert the labels in place\n",
        "\ty[flip_ix] = 1 - y[flip_ix]\n",
        "\treturn y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goIk99UrKyLR"
      },
      "source": [
        "def get_valid_labels(img):\n",
        "  return noisy_labels((0.8 - 1.1) * torch.rand(img.shape[0], 1, 1, 1) + 1.1)  # soft labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiuEqLsaK7Xe"
      },
      "source": [
        "def get_unvalid_labels(img):\n",
        "  return noisy_labels((0.0 - 0.3) * torch.rand(img.shape[0], 1, 1, 1) + 0.3)  # soft labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDKio5Na_7xl"
      },
      "source": [
        "class Discriminator(pl.LightningModule):\n",
        "  def __init__(self, ndf, nc):\n",
        "      super().__init__()\n",
        "      self.ndf = ndf\n",
        "      self.nc = nc\n",
        "\n",
        "      # input is (nc) x 128 x 128\n",
        "      # self.fc1 = nn.Sequential(\n",
        "      #     nn.Conv2d(in_channels=self.nc, out_channels=self.ndf, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "      #     nn.LeakyReLU(0.2)\n",
        "      # )\n",
        "\n",
        "      # input is (nc) x 64 x 64\n",
        "      self.fc1 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=self.nc, out_channels=self.ndf, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "           # nn.BatchNorm2d(self.ndf * 2),\n",
        "          nn.LeakyReLU(0.2)\n",
        "      )\n",
        "\n",
        "      # state size. (ndf) x 32 x 32\n",
        "      self.fc2 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=self.ndf, out_channels=self.ndf * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "          nn.BatchNorm2d(self.ndf * 2),\n",
        "          nn.LeakyReLU(0.2),\n",
        "          nn.Dropout(0.3)\n",
        "      )\n",
        "\n",
        "      # state size. (ndf*2) x 16 x 16\n",
        "      self.fc3 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=self.ndf * 2, out_channels=self.ndf * 4, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "          nn.BatchNorm2d(self.ndf * 4),\n",
        "          nn.LeakyReLU(0.2),\n",
        "          nn.Dropout(0.3)\n",
        "      )\n",
        "\n",
        "      # state size. (ndf*4) x 8 x 8\n",
        "      self.fc4 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=self.ndf * 4, out_channels=self.ndf * 8, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "          nn.BatchNorm2d(self.ndf * 8),\n",
        "          nn.LeakyReLU(0.2),\n",
        "          nn.Dropout(0.3)\n",
        "      )\n",
        "\n",
        "      # state size. (ndf*8) x 4 x 4\n",
        "      self.fc5 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=self.ndf * 8, out_channels=1, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "          nn.Sigmoid()\n",
        "      )\n",
        "\n",
        "      # state size. 1\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "    x = self.fc4(x)\n",
        "    x = self.fc5(x)\n",
        "    #x = self.fc6(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHU8nlJLACTW"
      },
      "source": [
        "class Generator(pl.LightningModule):\n",
        "  def __init__(self, latent_dim, ngf, nc):\n",
        "    super().__init__()\n",
        "    self.ngf = 16\n",
        "    self.n_features = latent_dim\n",
        "    self.nc = nc\n",
        "\n",
        "    # input is Z, going into a convolution\n",
        "    self.fc1 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels=self.n_features, out_channels=self.ngf * 8, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "        nn.BatchNorm2d(self.ngf * 8),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "    # state size. (ngf*8) x 4 x 4\n",
        "    self.fc2 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(self.ngf * 8, self.ngf * 4, 4, 2, 1, False),\n",
        "        nn.BatchNorm2d(self.ngf * 4),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "    # state size. (ngf*4) x 8 x 8\n",
        "    self.fc3 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(self.ngf * 4, self.ngf * 2, 4, 2, 1, False),\n",
        "        nn.BatchNorm2d(self.ngf * 2),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "    # state size. (ngf*2) x 16 x 16\n",
        "    self.fc4 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(self.ngf * 2, self.ngf, 4, 2, 1, False),\n",
        "        nn.BatchNorm2d(self.ngf),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "    # state size. (ngf) x 32 x 32\n",
        "    self.fc5 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels=self.ngf, out_channels=self.nc, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        #nn.BatchNorm2d(self.ngf),\n",
        "        #nn.LeakyReLU(0.2)\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "    # state size. (ngf) x 64 x 64\n",
        "    # self.fc6 = nn.Sequential(\n",
        "    #     nn.ConvTranspose2d(in_channels=self.ngf, out_channels=self.nc, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    #     nn.Tanh()\n",
        "    # )\n",
        "\n",
        "     # state size. (nc) x 128 x 128\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "    x = self.fc4(x)\n",
        "    x = self.fc5(x)\n",
        "    #x = self.fc6(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwokISNjJ0l0"
      },
      "source": [
        "class DCGAN(pl.LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super().__init__()\n",
        "        self.hparams = hparams\n",
        "\n",
        "        self.generator = Generator(hparams.latent_dim, hparams.ngf, hparams.nc)\n",
        "        self.discriminator = Discriminator(hparams.ndf, hparams.nc)\n",
        "        self.generator.apply(weights_init) # custom weight init\n",
        "        self.discriminator.apply(weights_init)\n",
        "\n",
        "        # cache for generated images\n",
        "        self.generated_imgs = None\n",
        "        self.last_imgs = None\n",
        "\n",
        "        # For experience replay\n",
        "        self.exp_replay = torch.tensor([])\n",
        "\n",
        "    def binary_cross_entropy(self, y_hat, y):\n",
        "        return F.binary_cross_entropy(y_hat, y)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.generator(x)\n",
        "\n",
        "    def training_step(self, batch, batch_nb, optimizer_idx):\n",
        "        std_gaussian = max(0, self.hparams.level_of_noise - ((self.hparams.level_of_noise * 2) * (self.current_epoch / self.hparams.epochs)))\n",
        "        #AddGaussianNoiseInst = AddGaussianNoise(std=std_gaussian) # the noise decays over time\n",
        "\n",
        "        img = batch[0]\n",
        "        #img = AddGaussianNoiseInst(img)\n",
        "        self.last_imgs = img\n",
        "\n",
        "        # Train Generator maximize log(D(G(z)))\n",
        "        if optimizer_idx == 0:\n",
        "            noise = torch.randn(img.shape[0], self.hparams.latent_dim, 1, 1)\n",
        "\n",
        "            self.generated_img = self(noise)\n",
        "            #self.generated_img = AddGaussianNoiseInst(self.generated_img)\n",
        "\n",
        "            g_loss = self.binary_cross_entropy(self.discriminator(self.generated_img), get_valid_labels(self.generated_img)) # valid labels is right to use here\n",
        "\n",
        "            tqdm_dict = {'g_loss': g_loss}\n",
        "            logs = {\"g_loss\": g_loss, \"std_gaussian\": std_gaussian}\n",
        "            return {\"loss\": g_loss, \"log\": logs, 'progress_bar': tqdm_dict}\n",
        "\n",
        "        # Train Discriminator maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        if optimizer_idx == 1:\n",
        "            d_loss = 0\n",
        "\n",
        "            # Experience replay\n",
        "            perm = torch.randperm(self.generated_img.size(0))  # Shuffeling\n",
        "            r_idx = perm[:max(1, self.hparams.experience_save_per_batch)]  # Getting the index\n",
        "            self.exp_replay = torch.cat((self.exp_replay, self.generated_img[r_idx]),\n",
        "                                        0).detach()  # Add our new example to the replay buffer\n",
        "\n",
        "            if self.exp_replay.size(0) >= self.hparams.experience_batch_size:  # when we have enough example from the past train on them\n",
        "                fake_loss = self.binary_cross_entropy(self.discriminator(self.exp_replay.detach()), get_unvalid_labels(self.exp_replay.detach()))\n",
        "\n",
        "                d_loss = fake_loss\n",
        "                self.exp_replay = torch.tensor([])\n",
        "\n",
        "                tqdm_dict = {'d_loss': d_loss}\n",
        "                logs = {\"d_loss\": d_loss, \"std_gaussian\": std_gaussian}\n",
        "                return {\"loss\": d_loss, \"log\": logs, 'progress_bar': tqdm_dict}\n",
        "\n",
        "            else:\n",
        "                real_loss = self.binary_cross_entropy(self.discriminator(img), get_valid_labels(img))\n",
        "\n",
        "                fake_loss = self.binary_cross_entropy(self.discriminator(self.generated_img.detach()), get_unvalid_labels(self.generated_img.detach()))\n",
        "\n",
        "                d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "                tqdm_dict = {'d_loss': d_loss}\n",
        "                logs = {\"d_exp_loss\": d_loss, \"std_gaussian\": std_gaussian}\n",
        "                return {\"loss\": d_loss, \"log\": logs, 'progress_bar': tqdm_dict}\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=self.hparams.lr,\n",
        "                                 betas=(self.hparams.b1, self.hparams.b2))\n",
        "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=self.hparams.lr,\n",
        "                                 betas=(self.hparams.b1, self.hparams.b2))\n",
        "\n",
        "        return opt_g, opt_d\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        transform = transforms.Compose([transforms.Resize((self.hparams.image_size, self.hparams.image_size)),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize([0.5], [0.5])\n",
        "                                        ])\n",
        "\n",
        "        train_dataset = torchvision.datasets.ImageFolder(\n",
        "            root=\"./drive/My Drive/datasets/ghibli_dataset_small_overfit/\",\n",
        "            transform=transform\n",
        "        )\n",
        "        return DataLoader(train_dataset, num_workers=self.hparams.num_workers, shuffle=True, batch_size=self.hparams.batch_size)\n",
        "        # transform = transforms.Compose([transforms.Resize((64, 64)),\n",
        "        #                             transforms.ToTensor(),\n",
        "        #                             transforms.Normalize([0.5], [0.5]),\n",
        "        #                             ])\n",
        "        # dataset = MNIST(os.getcwd(), train=True, download=True, transform=transform)\n",
        "\n",
        "        # rand_idx = torch.randperm(len(dataset)).tolist()\n",
        "        # rand_idx = rand_idx[:self.hparams.batch_size]\n",
        "\n",
        "        # subset_loader = torch.utils.data.DataLoader(dataset, batch_size=self.hparams.batch_size, sampler=torch.utils.data.SubsetRandomSampler(rand_idx), num_workers=self.hparams.num_workers)\n",
        "        # return subset_loader\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.current_epoch % self.hparams.save_train_image_every_epoch == 0:\n",
        "          perm = torch.randperm(self.last_imgs.size(0))\n",
        "          idx = perm[:1]\n",
        "          comet_logger.experiment.log_image(self.last_imgs[idx].squeeze(dim=0).permute(1, 2, 0), f'trained_on_this_image{self.current_epoch}', step=self.current_epoch)\n",
        "\n",
        "        if self.current_epoch % self.hparams.save_image_every_epoch == 0:\n",
        "            noise = torch.randn(4, self.hparams.latent_dim, 1, 1)\n",
        "\n",
        "            sample_img = self.generator(noise)\n",
        "            sample_img = sample_img.view(-1, self.hparams.nc, self.hparams.image_size, self.hparams.image_size)\n",
        "            grid = torchvision.utils.make_grid(sample_img, nrow=2)\n",
        "            comet_logger.experiment.log_image(grid.permute(1, 2, 0), f'generated_images_epoch{self.current_epoch}', step=self.current_epoch)\n",
        "            torchvision.utils.save_image(grid, f'{experiment_name}/images/generated_images_epoch{self.current_epoch}.png')\n",
        "\n",
        "        if self.current_epoch % self.hparams.save_model_every_epoch == 0:\n",
        "            trainer.save_checkpoint(checkpoint_folder + \"/\" + experiment_name + \"_epoch_\" + str(self.current_epoch) + \".ckpt\")\n",
        "            comet_logger.experiment.log_asset_folder(checkpoint_folder)\n",
        "\n",
        "            if dirpath.exists() and dirpath.is_dir():\n",
        "                shutil.rmtree(dirpath)\n",
        "\n",
        "            # creating checkpoint folder\n",
        "            access_rights = 0o755\n",
        "            os.makedirs(checkpoint_folder, access_rights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjlO0CUfAJfT"
      },
      "source": [
        "# Parameters\n",
        "experiment_name = \"GHIBLI_DCGAN_OVERFIT_64px\"\n",
        "dataset_name = \"GHIBLI_OVERFIT\"\n",
        "checkpoint_folder = \"DCGAN/\"\n",
        "tags = [\"DCGAN\", \"GHIBLI\", \"OVERFIT\", \"64x64\"]\n",
        "dirpath = Path(checkpoint_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEJUo3wAAMoq"
      },
      "source": [
        "# Hyperparameters\n",
        "from argparse import Namespace\n",
        "\n",
        "args = {\n",
        "    'batch_size': 10,\n",
        "    'lr': 0.0002,\n",
        "    'b1': 0.5,\n",
        "    'b2': 0.999,\n",
        "    'latent_dim': 125,\n",
        "    'level_of_noise': 0.1,\n",
        "    'epochs': 10000,\n",
        "    'ndf': 10,  # discriminator is slighly worse so that the discriminator doesnt become too good\n",
        "    'ngf': 16,\n",
        "    'experience_batch_size': 200,\n",
        "    'experience_save_per_batch': 2,\n",
        "    'save_model_every_epoch': 500,\n",
        "    'save_image_every_epoch': 2,\n",
        "    'num_workers': 3,\n",
        "    'nc': 3,\n",
        "    'image_size': 64,\n",
        "    'save_train_image_every_epoch': 100\n",
        "}\n",
        "\n",
        "hparams = Namespace(**args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVJbQ39RAORf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "38a77ede-288c-4816-b76c-a7e0e5f7b086"
      },
      "source": [
        "# init logger\n",
        "comet_logger = loggers.CometLogger(\n",
        "    api_key=\"\",\n",
        "    rest_api_key=\"\",\n",
        "    project_name=\"ghibli-gan\",\n",
        "    experiment_name=experiment_name,\n",
        "    #experiment_key=\"f23d00c0fe3448ee884bfbe3fc3923fd\"  # used for resuming trained id can be found in comet.ml\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:lightning:CometLogger will be initialized in online mode\n",
            "COMET INFO: old comet version (3.1.4) detected. current: 3.1.5 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/luposx/ghibli-gan/8ed4bf0b88ab4e9594a001439c653b99\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap-wZissAPgi"
      },
      "source": [
        "#defining net\n",
        "net = DCGAN(hparams)\n",
        "\n",
        "#logging\n",
        "comet_logger.experiment.set_model_graph(str(net))\n",
        "comet_logger.experiment.add_tags(tags=tags)\n",
        "comet_logger.experiment.log_dataset_info(dataset_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctKzyQ9xATZ3"
      },
      "source": [
        "# deleting the checkpoint folder\n",
        "if dirpath.exists() and dirpath.is_dir():\n",
        "    shutil.rmtree(dirpath)\n",
        "\n",
        "# creating checkpoint folder\n",
        "access_rights = 0o755\n",
        "os.makedirs(checkpoint_folder, access_rights)\n",
        "\n",
        "dirpath2 = Path(f'{experiment_name}/images')\n",
        "if dirpath2.exists() and dirpath2.is_dir():\n",
        "                shutil.rmtree(dirpath2)\n",
        "os.makedirs(dirpath2, access_rights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOI2ebfVAUaH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "579e5a9ef6ef4678a9b0a0fa89634555",
            "55ca991857024119aebfdf49f2b7f637",
            "1b3defa8f2b34bdcbce4fdfcf2b1d254",
            "74bd43ba14f2477c8d8595bfc06339f6",
            "0393545ac63d4070a924b9ceae6f7e80",
            "fb43ce96d8af4988a904a36154bc6bf4",
            "433ee25860b645e180a2f6d5ecf0cc5d",
            "3b0c3392e2254346979fda24b9f16a0e"
          ]
        },
        "outputId": "42c57a99-acc5-40ea-d90a-29c7732a975b"
      },
      "source": [
        "trainer = pl.Trainer(#resume_from_checkpoint=\"GHIBLI_DCGAN_OVERFIT_64px_epoch_6000.ckpt\",\n",
        "                     logger=comet_logger,\n",
        "                     max_epochs=args[\"epochs\"]\n",
        "                     )\n",
        "trainer.fit(net)\n",
        "trainer.save_checkpoint(checkpoint_folder + \"/\" + experiment_name + \"_epoch_\" + str(args[\"epochs\"]) + \".ckpt\")\n",
        "comet_logger.experiment.log_asset_folder(checkpoint_folder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:lightning:\n",
            "   | Name                | Type            | Params\n",
            "----------------------------------------------------\n",
            "0  | generator           | Generator       | 429 K \n",
            "1  | generator.fc1       | Sequential      | 256 K \n",
            "2  | generator.fc1.0     | ConvTranspose2d | 256 K \n",
            "3  | generator.fc1.1     | BatchNorm2d     | 256   \n",
            "4  | generator.fc1.2     | LeakyReLU       | 0     \n",
            "5  | generator.fc2       | Sequential      | 131 K \n",
            "6  | generator.fc2.0     | ConvTranspose2d | 131 K \n",
            "7  | generator.fc2.1     | BatchNorm2d     | 128   \n",
            "8  | generator.fc2.2     | LeakyReLU       | 0     \n",
            "9  | generator.fc3       | Sequential      | 32 K  \n",
            "10 | generator.fc3.0     | ConvTranspose2d | 32 K  \n",
            "11 | generator.fc3.1     | BatchNorm2d     | 64    \n",
            "12 | generator.fc3.2     | LeakyReLU       | 0     \n",
            "13 | generator.fc4       | Sequential      | 8 K   \n",
            "14 | generator.fc4.0     | ConvTranspose2d | 8 K   \n",
            "15 | generator.fc4.1     | BatchNorm2d     | 32    \n",
            "16 | generator.fc4.2     | LeakyReLU       | 0     \n",
            "17 | generator.fc5       | Sequential      | 768   \n",
            "18 | generator.fc5.0     | ConvTranspose2d | 768   \n",
            "19 | generator.fc5.1     | Tanh            | 0     \n",
            "20 | discriminator       | Discriminator   | 69 K  \n",
            "21 | discriminator.fc1   | Sequential      | 480   \n",
            "22 | discriminator.fc1.0 | Conv2d          | 480   \n",
            "23 | discriminator.fc1.1 | LeakyReLU       | 0     \n",
            "24 | discriminator.fc2   | Sequential      | 3 K   \n",
            "25 | discriminator.fc2.0 | Conv2d          | 3 K   \n",
            "26 | discriminator.fc2.1 | BatchNorm2d     | 40    \n",
            "27 | discriminator.fc2.2 | LeakyReLU       | 0     \n",
            "28 | discriminator.fc2.3 | Dropout         | 0     \n",
            "29 | discriminator.fc3   | Sequential      | 12 K  \n",
            "30 | discriminator.fc3.0 | Conv2d          | 12 K  \n",
            "31 | discriminator.fc3.1 | BatchNorm2d     | 80    \n",
            "32 | discriminator.fc3.2 | LeakyReLU       | 0     \n",
            "33 | discriminator.fc3.3 | Dropout         | 0     \n",
            "34 | discriminator.fc4   | Sequential      | 51 K  \n",
            "35 | discriminator.fc4.0 | Conv2d          | 51 K  \n",
            "36 | discriminator.fc4.1 | BatchNorm2d     | 160   \n",
            "37 | discriminator.fc4.2 | LeakyReLU       | 0     \n",
            "38 | discriminator.fc4.3 | Dropout         | 0     \n",
            "39 | discriminator.fc5   | Sequential      | 1 K   \n",
            "40 | discriminator.fc5.0 | Conv2d          | 1 K   \n",
            "41 | discriminator.fc5.1 | Sigmoid         | 0     \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "579e5a9ef6ef4678a9b0a0fa89634555",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/warnings.py:18: RuntimeWarning: Displayed epoch numbers in the progress bar start from \"1\" until v0.6.x, but will start from \"0\" in v0.8.0.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "COMET ERROR: File could not be uploaded\n",
            "INFO:lightning:Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "COMET INFO: ---------------------------\n",
            "COMET INFO: Comet.ml Experiment Summary\n",
            "COMET INFO: ---------------------------\n",
            "COMET INFO:   Data:\n",
            "COMET INFO:     display_summary_level : 1\n",
            "COMET INFO:     url                   : https://www.comet.ml/luposx/ghibli-gan/8ed4bf0b88ab4e9594a001439c653b99\n",
            "COMET INFO:   Metrics [count] (min, max):\n",
            "COMET INFO:     d_loss [8790]       : (0.15617361664772034, 1.1096616983413696)\n",
            "COMET INFO:     g_loss [8790]       : (0.5527005195617676, 3.2761874198913574)\n",
            "COMET INFO:     std_gaussian [8790] : (0, 0.1)\n",
            "COMET INFO:   Others:\n",
            "COMET INFO:     Name         : GHIBLI_DCGAN_OVERFIT_64px\n",
            "COMET INFO:     dataset_info : GHIBLI_OVERFIT\n",
            "COMET INFO:   Parameters:\n",
            "COMET INFO:     b1                           : 0.5\n",
            "COMET INFO:     b2                           : 0.999\n",
            "COMET INFO:     batch_size                   : 10\n",
            "COMET INFO:     epochs                       : 10000\n",
            "COMET INFO:     experience_batch_size        : 200\n",
            "COMET INFO:     experience_save_per_batch    : 2\n",
            "COMET INFO:     image_size                   : 64\n",
            "COMET INFO:     latent_dim                   : 125\n",
            "COMET INFO:     level_of_noise               : 0.1\n",
            "COMET INFO:     lr                           : 0.0002\n",
            "COMET INFO:     nc                           : 3\n",
            "COMET INFO:     ndf                          : 10\n",
            "COMET INFO:     ngf                          : 16\n",
            "COMET INFO:     num_workers                  : 3\n",
            "COMET INFO:     save_image_every_epoch       : 2\n",
            "COMET INFO:     save_model_every_epoch       : 500\n",
            "COMET INFO:     save_train_image_every_epoch : 100\n",
            "COMET INFO:   Uploads [count]:\n",
            "COMET INFO:     asset [18]          : 18\n",
            "COMET INFO:     code                : 1 (13 KB)\n",
            "COMET INFO:     environment details : 1\n",
            "COMET INFO:     filename            : 1\n",
            "COMET INFO:     images [4484]       : 4484\n",
            "COMET INFO:     installed packages  : 1\n",
            "COMET INFO:     model graph         : 1\n",
            "COMET INFO:     os packages         : 1\n",
            "COMET INFO: ---------------------------\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: Uploading stats to Comet before program termination (may take several seconds)\n",
            "COMET INFO: old comet version (3.1.4) detected. current: 3.1.5 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/luposx/ghibli-gan/8ed4bf0b88ab4e9594a001439c653b99\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('GHIBLI_DCGAN_OVERFIT_64px_epoch_10000.ckpt',\n",
              "  {'api': 'https://www.comet.ml/api/rest/v2/experiment/asset/get-asset?assetId=62325b5f4d0b4cae8be2d915c56654cb&experimentKey=8ed4bf0b88ab4e9594a001439c653b99',\n",
              "   'assetId': '62325b5f4d0b4cae8be2d915c56654cb',\n",
              "   'web': 'https://www.comet.ml/api/asset/download?assetId=62325b5f4d0b4cae8be2d915c56654cb&experimentKey=8ed4bf0b88ab4e9594a001439c653b99'})]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5aBf9LM8Lnn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}