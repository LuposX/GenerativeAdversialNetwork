{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_V6_2_64px.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdkl0fySfZZW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "d60ed407-29b7-41b8-ce2e-61c00bb5f540"
      },
      "source": [
        "!pip install comet_ml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: comet_ml in /usr/local/lib/python3.6/dist-packages (3.1.6)\n",
            "Requirement already satisfied: netifaces>=0.10.7 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.10.9)\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.6.0)\n",
            "Requirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.57.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.12.0)\n",
            "Requirement already satisfied: comet-git-pure>=0.19.11 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.19.16)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (3.7.4.2)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (7.352.0)\n",
            "Requirement already satisfied: everett[ini]>=1.0.1; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.0.2)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (2020.4.5.1)\n",
            "Requirement already satisfied: configobj; extra == \"ini\" in /usr/local/lib/python3.6/dist-packages (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet_ml) (5.0.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL2WMyUhfkyX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "f06978a8-f279-4782-bcbf-0e16b5c78351"
      },
      "source": [
        "!pip install pytorch_lightning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.6/dist-packages (0.7.5)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (2.2.1)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (1.5.0+cu101)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (1.18.3)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (0.18.2)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (4.46.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (0.34.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.7.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (3.2.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (3.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (46.1.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.12.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (0.4.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.28.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning) (1.6.0.post3)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (3.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (2020.4.5.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aOFSycYfmFf"
      },
      "source": [
        "# used fo TPU\n",
        "# Uncomment if you want to use TPU\n",
        "# ------------------------------------------------------------------\n",
        "# import collections\n",
        "# from datetime import datetime, timedelta\n",
        "# import os\n",
        "# import requests\n",
        "# import threading\n",
        "\n",
        "# _VersionConfig = collections.namedtuple('_VersionConfig', 'wheels,server')\n",
        "# VERSION = \"xrt==1.15.0\"  # @param [\"xrt==1.15.0\", \"torch_xla==nightly\"]\n",
        "# CONFIG = {\n",
        "#     'xrt==1.15.0': _VersionConfig('1.15', '1.15.0'),\n",
        "#     'torch_xla==nightly': _VersionConfig('nightly', 'XRT-dev{}'.format(\n",
        "#         (datetime.today() - timedelta(1)).strftime('%Y%m%d'))),\n",
        "# }[VERSION]\n",
        "# DIST_BUCKET = 'gs://tpu-pytorch/wheels'\n",
        "# TORCH_WHEEL = 'torch-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
        "# TORCH_XLA_WHEEL = 'torch_xla-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
        "# TORCHVISION_WHEEL = 'torchvision-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
        "\n",
        "# # Update TPU XRT version\n",
        "# def update_server_xrt():\n",
        "#     print('Updating server-side XRT to {} ...'.format(CONFIG.server))\n",
        "#     url = 'http://{TPU_ADDRESS}:8475/requestversion/{XRT_VERSION}'.format(\n",
        "#         TPU_ADDRESS=os.environ['COLAB_TPU_ADDR'].split(':')[0],\n",
        "#         XRT_VERSION=CONFIG.server,\n",
        "#     )\n",
        "#     print('Done updating server-side XRT: {}'.format(requests.post(url)))\n",
        "\n",
        "\n",
        "# update = threading.Thread(target=update_server_xrt)\n",
        "# update.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHLEBnnSfosm"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import loggers\n",
        "\n",
        "from numpy.random import choice\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "from collections import OrderedDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjjEWS1Lfthl"
      },
      "source": [
        "# lets hope this fixes the bug that my pc crashes after reconnecting\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmTaKo7mfwxc"
      },
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx70EX9wfx1D"
      },
      "source": [
        "# randomly flip some labels\n",
        "def noisy_labels(y, p_flip=0.05):  # # flip labels with 5% probability\n",
        "    # determine the number of labels to flip\n",
        "    n_select = int(p_flip * y.shape[0])\n",
        "    # choose labels to flip\n",
        "    flip_ix = choice([i for i in range(y.shape[0])], size=n_select)\n",
        "    # invert the labels in place\n",
        "    y[flip_ix] = 1 - y[flip_ix]\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noCnaCJZfzHm"
      },
      "source": [
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0.0, std=0.1):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzAjUIW5f0kd"
      },
      "source": [
        "def resize2d(img, size):\n",
        "    return F.adaptive_avg_pool2d(img, size).data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EptHLAyIf3xB"
      },
      "source": [
        "def get_valid_labels(img):\n",
        "    return (0.8 - 1.1) * torch.rand(img.shape[0], 1, 1, 1) + 1.1  # soft labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v-p-xCFf5HG"
      },
      "source": [
        "def get_unvalid_labels(img):\n",
        "    return noisy_labels((0.0 - 0.3) * torch.rand(img.shape[0], 1, 1, 1) + 0.3)  # soft labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2amoqoiFf6WO"
      },
      "source": [
        "class Generator(pl.LightningModule):\n",
        "    def __init__(self, ngf, nc, latent_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngf = ngf\n",
        "        self.latent_dim = latent_dim\n",
        "        self.nc = nc\n",
        "\n",
        "        self.fc0 = nn.Sequential(\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.utils.spectral_norm(nn.ConvTranspose2d(latent_dim, ngf * 8, 4, 1, 0, bias=False)),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.BatchNorm2d(ngf * 8)\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Sequential(\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.utils.spectral_norm(nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False)),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.BatchNorm2d(ngf * 4)\n",
        "        )\n",
        "\n",
        "        self.fc2 = nn.Sequential(\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.utils.spectral_norm(nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False)),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.BatchNorm2d(ngf * 2)\n",
        "        )\n",
        "\n",
        "        self.fc3 = nn.Sequential(\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.utils.spectral_norm(nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False)),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.BatchNorm2d(ngf)\n",
        "        )\n",
        "\n",
        "        self.fc4 = nn.Sequential(\n",
        "            # state size. (nc) x 64 x 64\n",
        "            nn.utils.spectral_norm(nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False)),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # state size. (nc) x 128 x 128\n",
        "\n",
        "        # For Multi-Scale Gradient\n",
        "        # Converting the intermediate layers into images\n",
        "        self.fc0_r = nn.Conv2d(ngf * 8, self.nc, 1)\n",
        "        self.fc1_r = nn.Conv2d(ngf * 4, self.nc, 1)\n",
        "        self.fc2_r = nn.Conv2d(ngf * 2, self.nc, 1)\n",
        "        self.fc3_r = nn.Conv2d(ngf, self.nc, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x_0 = self.fc0(input)\n",
        "        x_1 = self.fc1(x_0)\n",
        "        x_2 = self.fc2(x_1)\n",
        "        x_3 = self.fc3(x_2)\n",
        "        x_4 = self.fc4(x_3)\n",
        "\n",
        "        # For Multi-Scale Gradient\n",
        "        # Converting the intermediate layers into images\n",
        "        x_0_r = self.fc0_r(x_0)\n",
        "        x_1_r = self.fc1_r(x_1)\n",
        "        x_2_r = self.fc2_r(x_2)\n",
        "        x_3_r = self.fc3_r(x_3)\n",
        "\n",
        "        return x_4, x_0_r, x_1_r, x_2_r, x_3_r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PFMmdgzf8Xx"
      },
      "source": [
        "class Discriminator(pl.LightningModule):\n",
        "    def __init__(self, ndf, nc):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.nc = nc\n",
        "        self.ndf = ndf\n",
        "\n",
        "        self.fc0 = nn.Sequential(\n",
        "            # state size. (ndf) x 64 x 64\n",
        "            nn.utils.spectral_norm(nn.Conv2d(nc, ndf, 4, 2, 1, bias=False)),\n",
        "            # \"+ nc\" because of multi scale gradient\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Sequential(\n",
        "            # state size. (ndf*2) x 32 x 32\n",
        "            nn.utils.spectral_norm(nn.Conv2d(ndf + nc, ndf * 2, 4, 2, 1, bias=False)),\n",
        "            # \"+ nc\" because of multi scale gradient\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.BatchNorm2d(ndf * 2)\n",
        "        )\n",
        "\n",
        "        self.fc2 = nn.Sequential(\n",
        "            # state size. (ndf*4) x 16 x 16e\n",
        "            nn.utils.spectral_norm(nn.Conv2d(ndf * 2 + nc, ndf * 4, 4, 2, 1, bias=False)),\n",
        "            # \"+ nc\" because of multi scale gradient\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "        )\n",
        "\n",
        "        self.fc3 = nn.Sequential(\n",
        "            # state size. (ndf*8) x 8 x 8\n",
        "            nn.utils.spectral_norm(nn.Conv2d(ndf * 4 + nc, ndf * 8, 4, 2, 1, bias=False)),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.BatchNorm2d(ndf * 8)\n",
        "        )\n",
        "\n",
        "        self.fc4 = nn.Sequential(\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.utils.spectral_norm(nn.Conv2d(ndf * 8 + nc, 1, 4, 1, 0, bias=False)),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # state size. 1 x 1 x 1\n",
        "\n",
        "    def forward(self, input, detach_or_not):\n",
        "        # When we train i ncombination with generator we use multi scale gradient.\n",
        "        x, x_0_r, x_1_r, x_2_r, x_3_r = input\n",
        "        if detach_or_not:\n",
        "            x = x.detach()\n",
        "\n",
        "        x_0 = self.fc0(x)\n",
        "\n",
        "        x_0 = torch.cat((x_0, x_3_r), dim=1)  # Concat Multi-Scale Gradient\n",
        "        x_1 = self.fc1(x_0)\n",
        "\n",
        "        x_1 = torch.cat((x_1, x_2_r), dim=1)  # Concat Multi-Scale Gradient\n",
        "        x_2 = self.fc2(x_1)\n",
        "\n",
        "        x_2 = torch.cat((x_2, x_1_r), dim=1)  # Concat Multi-Scale Gradient\n",
        "        x_3 = self.fc3(x_2)\n",
        "\n",
        "        x_3 = torch.cat((x_3, x_0_r), dim=1)  # Concat Multi-Scale Gradient\n",
        "        x_4 = self.fc4(x_3)\n",
        "\n",
        "        return x_4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIPAhNKVf-oF"
      },
      "source": [
        "class DCGAN(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, hparams, logger, checkpoint_folder, experiment_name):\n",
        "        super().__init__()\n",
        "        self.hparams = hparams\n",
        "        self.logger = logger  # only compatible with comet_logger at the moment\n",
        "        self.checkpoint_folder = checkpoint_folder\n",
        "        self.experiment_name = experiment_name\n",
        "\n",
        "        # networks\n",
        "        self.generator = Generator(ngf=hparams.ngf, nc=hparams.nc, latent_dim=hparams.latent_dim)\n",
        "        self.discriminator = Discriminator(ndf=hparams.ndf, nc=hparams.nc)\n",
        "        self.generator.apply(weights_init)\n",
        "        self.discriminator.apply(weights_init)\n",
        "\n",
        "        # cache for generated images\n",
        "        self.generated_imgs = None\n",
        "        self.last_imgs = None\n",
        "\n",
        "        # For experience replay\n",
        "        self.exp_replay_dis = torch.tensor([])\n",
        "\n",
        "        # creating checkpoint folder\n",
        "        dirpath = Path(self.checkpoint_folder)\n",
        "        if not dirpath.exists():\n",
        "            os.makedirs(dirpath, 0o755)\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.generator(z)\n",
        "\n",
        "    def adversarial_loss(self, y_hat, y):\n",
        "        return F.binary_cross_entropy(y_hat, y)\n",
        "\n",
        "    def training_step(self, batch, batch_nb, optimizer_idx):\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        # For adding Instance noise for more visit: https://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/\n",
        "        std_gaussian = max(0, self.hparams.level_of_noise - (\n",
        "                (self.hparams.level_of_noise * 2) * (self.current_epoch / self.hparams.epochs)))\n",
        "        AddGaussianNoiseInst = AddGaussianNoise(std=std_gaussian)  # the noise decays over time\n",
        "\n",
        "        imgs, _ = batch\n",
        "        imgs = AddGaussianNoiseInst(imgs)  # Adding instance noise to real images\n",
        "        self.last_imgs = imgs\n",
        "\n",
        "        # train generator\n",
        "        if optimizer_idx == 0:\n",
        "            # sample noise\n",
        "            z = torch.randn(imgs.shape[0], self.hparams.latent_dim, 1, 1)\n",
        "\n",
        "            # generate images\n",
        "            self.generated_imgs = self(z)\n",
        "\n",
        "            # ground truth result (ie: all fake)\n",
        "            g_loss = self.adversarial_loss(self.discriminator(self.generated_imgs, False), get_valid_labels(\n",
        "                self.generated_imgs[0]))  # adversarial loss is binary cross-entropy; [0] is the image of the last layer\n",
        "\n",
        "            tqdm_dict = {'g_loss': g_loss}\n",
        "            log = {'g_loss': g_loss, \"std_gaussian\": std_gaussian}\n",
        "            output = OrderedDict({\n",
        "                'loss': g_loss,\n",
        "                'progress_bar': tqdm_dict,\n",
        "                'log': log\n",
        "            })\n",
        "            return output\n",
        "\n",
        "        # train discriminator\n",
        "        if optimizer_idx == 1:\n",
        "            # Measure discriminator's ability to classify real from generated samples\n",
        "            # how well can it label as real?\n",
        "            real_loss = self.adversarial_loss(\n",
        "                self.discriminator([imgs, resize2d(imgs, 4), resize2d(imgs, 8), resize2d(imgs, 16), resize2d(imgs, 32)], False), get_valid_labels(imgs))\n",
        "\n",
        "            fake_loss = self.adversarial_loss(self.discriminator(self.generated_imgs, True), get_unvalid_labels(\n",
        "                self.generated_imgs[0]))  # how well can it label as fake?; [0] is the image of the last layer\n",
        "\n",
        "            # discriminator loss is the average of these\n",
        "            d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "            tqdm_dict = {'d_loss': d_loss}\n",
        "            log = {'d_loss': d_loss, \"std_gaussian\": std_gaussian}\n",
        "            output = OrderedDict({\n",
        "                'loss': d_loss,\n",
        "                'progress_bar': tqdm_dict,\n",
        "                'log': log\n",
        "            })\n",
        "            return output\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        lr_gen = self.hparams.lr_gen\n",
        "        lr_dis = self.hparams.lr_dis\n",
        "        b1 = self.hparams.b1\n",
        "        b2 = self.hparams.b2\n",
        "\n",
        "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr_gen, betas=(b1, b2))\n",
        "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr_dis, betas=(b1, b2))\n",
        "        return [opt_g, opt_d], []\n",
        "\n",
        "    def backward(self, trainer, loss, optimizer, optimizer_idx: int) -> None:\n",
        "        loss.backward(retain_graph=True)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        transform = transforms.Compose([transforms.Resize((self.hparams.image_size, self.hparams.image_size)),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize([0.5], [0.5])])\n",
        "        dataset = torchvision.datasets.MNIST(os.getcwd(), train=True, download=True, transform=transform)\n",
        "        return DataLoader(dataset, num_workers=self.hparams.num_workers, shuffle=True, batch_size=self.hparams.batch_size)\n",
        "        # transform = transforms.Compose([transforms.Resize((self.hparams.image_size, self.hparams.image_size)),\n",
        "        #                                 transforms.ToTensor(),\n",
        "        #                                 transforms.Normalize([0.5], [0.5])\n",
        "        #                                 ])\n",
        "\n",
        "        # train_dataset = torchvision.datasets.ImageFolder(\n",
        "        #     root=\"./drive/My Drive/datasets/flower_dataset/\",\n",
        "        #     # root=\"./drive/My Drive/datasets/ghibli_dataset_small_overfit/\",\n",
        "        #     transform=transform\n",
        "        # )\n",
        "        # return DataLoader(train_dataset, num_workers=self.hparams.num_workers, shuffle=True,\n",
        "        #                   batch_size=self.hparams.batch_size)\n",
        "        # transform = transforms.Compose([transforms.Resize((self.hparams.image_size, self.hparams.image_size)),\n",
        "        #                                 transforms.ToTensor(),\n",
        "        #                                 transforms.Normalize([0.5], [0.5])\n",
        "        #                                 ])\n",
        "\n",
        "        # train_dataset = torchvision.datasets.ImageFolder(\n",
        "        #     root=\"ghibli_dataset_small_overfit/\",\n",
        "        #     transform=transform\n",
        "        # )\n",
        "        # return DataLoader(train_dataset, num_workers=self.hparams.num_workers, shuffle=True,\n",
        "        #                   batch_size=self.hparams.batch_size)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        z = torch.randn(4, self.hparams.latent_dim, 1, 1)\n",
        "        # match gpu device (or keep as cpu)\n",
        "        if self.on_gpu:\n",
        "            z = z.cuda(self.last_imgs.device.index)\n",
        "\n",
        "        # log sampled images\n",
        "        sample_imgs = self.generator(z)[0]\n",
        "        sample_imgs = sample_imgs.view(-1, self.hparams.nc, self.hparams.image_size, self.hparams.image_size)\n",
        "\n",
        "\n",
        "        grid = torchvision.utils.make_grid(sample_imgs, nrow=2)\n",
        "        grid = grid.permute(1, 2, 0)\n",
        "        self.logger.experiment.log_image(grid, f'generated_images_epoch{self.current_epoch}', step=self.current_epoch)\n",
        "\n",
        "        # save model\n",
        "        if self.current_epoch % self.hparams.save_model_every_epoch == 0:\n",
        "            trainer.save_checkpoint(\n",
        "                self.checkpoint_folder + \"/\" + self.experiment_name + \"_epoch_\" + str(self.current_epoch) + \".ckpt\")\n",
        "            comet_logger.experiment.log_asset_folder(self.checkpoint_folder, step=self.current_epoch)\n",
        "\n",
        "            # Deleting the folder where we saved the model so that we dont upload a thing twice\n",
        "            dirpath = Path(self.checkpoint_folder)\n",
        "            if dirpath.exists() and dirpath.is_dir():\n",
        "                shutil.rmtree(dirpath)\n",
        "\n",
        "            # creating checkpoint folder\n",
        "            access_rights = 0o755\n",
        "            os.makedirs(dirpath, access_rights)\n",
        "\n",
        "    def on_train_end(self):\n",
        "        trainer.save_checkpoint(\n",
        "            self.checkpoint_folder + \"/\" + self.experiment_name + \"_epoch_\" + str(self.current_epoch) + \".ckpt\")\n",
        "        comet_logger.experiment.log_asset_folder(self.checkpoint_folder, step=self.current_epoch)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpLirisygB7J"
      },
      "source": [
        "from argparse import Namespace\n",
        "\n",
        "args = {\n",
        "    'batch_size': 64, # batch size\n",
        "    'lr_gen': 0.0003,  # TTUR;learnin rate of both networks; tested value: 0.0002\n",
        "    'lr_dis': 0.0003,  # TTUR;learnin rate of both networks; tested value: 0.0002\n",
        "    'b1': 0.5,  # Momentum for adam; tested value(dcgan paper): 0.5\n",
        "    'b2': 0.999,  # Momentum for adam; tested value(dcgan paper): 0.999\n",
        "    'latent_dim': 256,  # tested value which worked(in V4_1): 100\n",
        "    'nc': 1,  # number of color channels\n",
        "    'ndf': 32,  # number of discriminator features\n",
        "    'ngf': 32,  # number of generator features\n",
        "    'epochs': 10,  # the maxima lamount of epochs the algorith should run\n",
        "    'save_model_every_epoch': 1,  # how often we save our model\n",
        "    'image_size': 64, # size of the image\n",
        "    'num_workers': 3,\n",
        "    'level_of_noise': 0.1,  # how much instance noise we introduce(std; tested value: 0.15 and 0.1\n",
        "    'experience_save_per_batch': 1,  # this value should be very low; tested value which works: 1\n",
        "    'experience_batch_size': 50  # this value shouldnt be too high; tested value which works: 50\n",
        "}\n",
        "hparams = Namespace(**args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZiLF4R3gDc1"
      },
      "source": [
        "# Parameters\n",
        "experiment_name = \"DCGAN_6_2_MNIST\"\n",
        "dataset_name = \"mnist\"\n",
        "checkpoint_folder = \"DCGAN/\"\n",
        "tags = [\"DCGAN\", \"64x64\"]\n",
        "dirpath = Path(checkpoint_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cjm2c5kPgEvy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "721466f4-ece6-4bd5-da9b-d377e796c934"
      },
      "source": [
        "# init logger\n",
        "comet_logger = loggers.CometLogger(\n",
        "    api_key=\"\",\n",
        "    rest_api_key=\"\",\n",
        "    project_name=\"gan-mnist\",\n",
        "    experiment_name=experiment_name,\n",
        "    # experiment_key=\"222a685177474cb9b358b5ee642564dc\"  # used for resuming trained id can be found in comet.ml\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:lightning:CometLogger will be initialized in online mode\n",
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/luposx/gan-mnist/e3960656d19e4a6982bf3dd445da182a\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWAfRXsVgGTX"
      },
      "source": [
        "# defining net\n",
        "net = DCGAN(hparams, comet_logger, checkpoint_folder, experiment_name)\n",
        "\n",
        "# logging\n",
        "comet_logger.experiment.set_model_graph(str(net))\n",
        "comet_logger.experiment.add_tags(tags=tags)\n",
        "comet_logger.experiment.log_dataset_info(dataset_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D_VasOmgJ1N"
      },
      "source": [
        "trainer = pl.Trainer( # resume_from_checkpoint=\"DCGAN_V4_2_GHIBLI_epoch_999.ckpt\",\n",
        "    logger=comet_logger,\n",
        "    max_epochs=args[\"epochs\"]\n",
        ")\n",
        "\n",
        "trainer.fit(net)\n",
        "\n",
        "comet_logger.experiment.end()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvVHsHlfE6ht"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}